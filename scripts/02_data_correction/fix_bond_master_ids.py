"""
æ—¢å­˜155ä»¶ã®bond_master_idã‚’ä¿®æ­£
BOND_001 â†’ æ­£ã—ã„bond_master_idã«æ›´æ–°

Day 4å®Œäº†ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆç‰¹æ®Šå‚µåˆ¸å¯¾å¿œï¼‰
"""

import sys
import logging
from pathlib import Path
from datetime import datetime
from google.cloud import bigquery
from google.oauth2 import service_account

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®šï¼ˆparsersã®INFOãƒ­ã‚°ã‚’æŠ‘åˆ¶ï¼‰
logging.basicConfig(level=logging.WARNING)

# ãƒ‘ã‚¹ã®è¨­å®š
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from parsers.issue_extractor import IssueExtractor
from parsers.table_parser import TableParser

# è¨­å®š
PROJECT_ID = "jgb2023"
DATASET_ID = "20251019"
BOND_MASTER_TABLE = "bonds_master"
DATA_DIR = Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿")

# å‚µåˆ¸ç¨®é¡ã¨bond_master_idã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå…¨è§’ãƒ»åŠè§’ä¸¡å¯¾å¿œ + ç‰¹æ®Šå‚µåˆ¸å¯¾å¿œï¼‰
BOND_TYPE_TO_MASTER_ID = {
    # é€šå¸¸ã®åˆ©ä»˜å›½å‚µ
    'ï¼’å¹´': 'BOND_KENSETSU_2Y',
    '2å¹´': 'BOND_KENSETSU_2Y',
    'ï¼•å¹´': 'BOND_KENSETSU_5Y',
    '5å¹´': 'BOND_KENSETSU_5Y',
    '10å¹´': 'BOND_KENSETSU_10Y',
    '20å¹´': 'BOND_KENSETSU_20Y',
    '30å¹´': 'BOND_KENSETSU_30Y',
    '40å¹´': 'BOND_KENSETSU_40Y',
    # å€‹äººå‘ã‘å›½å‚µ
    'å›ºå®šãƒ»ï¼“å¹´': 'BOND_KOJIN_FIXED_3Y',
    'å›ºå®šãƒ»3å¹´': 'BOND_KOJIN_FIXED_3Y',
    'å›ºå®šãƒ»ï¼•å¹´': 'BOND_KOJIN_FIXED_5Y',
    'å›ºå®šãƒ»5å¹´': 'BOND_KOJIN_FIXED_5Y',
    'å¤‰å‹•ãƒ»10å¹´': 'BOND_KOJIN_VARIABLE_10Y',
    # å›½åº«çŸ­æœŸè¨¼åˆ¸
    'çŸ­æœŸ': 'BOND_TANKI',
    'çŸ­æœŸè¨¼åˆ¸': 'BOND_TANKI',
    'çŸ­æœŸå¹´': 'BOND_TANKI',  # æŠ½å‡ºãƒŸã‚¹å¯¾å¿œï¼ˆå¿µã®ãŸã‚ï¼‰
    # ç‰©ä¾¡é€£å‹•å‚µ
    'ç‰©ä¾¡é€£å‹•ãƒ»10å¹´': 'BOND_BUKKA_10Y',
}

# bonds_masterã«è¿½åŠ ã™ã‚‹ç‰¹æ®Šå‚µåˆ¸ãƒã‚¹ã‚¿ãƒ¼
SPECIAL_BOND_MASTERS = {
    'BOND_KOJIN_FIXED_3Y': {
        'bond_id': 'BOND_KOJIN_FIXED_3Y',
        'bond_name': 'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆå›ºå®šãƒ»3å¹´ï¼‰',
        'bond_type': 'å€‹äººå‘ã‘å›½å‚µ',
        'maturity_years': 3.0,
        'maturity_type': 'å›ºå®šãƒ»3å¹´',
        'issue_method': 'å€‹äººå‘ã‘',
        'interest_type': 'å›ºå®šåˆ©ä»˜',
        'interest_payment': 'å¹´2å›',
        'min_denomination': 10000,
        'description': 'å€‹äººå‘ã‘å›½å‚µãƒ»å›ºå®šé‡‘åˆ©3å¹´ç‰©',
        'is_active': True
    },
    'BOND_KOJIN_FIXED_5Y': {
        'bond_id': 'BOND_KOJIN_FIXED_5Y',
        'bond_name': 'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆå›ºå®šãƒ»5å¹´ï¼‰',
        'bond_type': 'å€‹äººå‘ã‘å›½å‚µ',
        'maturity_years': 5.0,
        'maturity_type': 'å›ºå®šãƒ»5å¹´',
        'issue_method': 'å€‹äººå‘ã‘',
        'interest_type': 'å›ºå®šåˆ©ä»˜',
        'interest_payment': 'å¹´2å›',
        'min_denomination': 10000,
        'description': 'å€‹äººå‘ã‘å›½å‚µãƒ»å›ºå®šé‡‘åˆ©5å¹´ç‰©',
        'is_active': True
    },
    'BOND_KOJIN_VARIABLE_10Y': {
        'bond_id': 'BOND_KOJIN_VARIABLE_10Y',
        'bond_name': 'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆå¤‰å‹•ãƒ»10å¹´ï¼‰',
        'bond_type': 'å€‹äººå‘ã‘å›½å‚µ',
        'maturity_years': 10.0,
        'maturity_type': 'å¤‰å‹•ãƒ»10å¹´',
        'issue_method': 'å€‹äººå‘ã‘',
        'interest_type': 'å¤‰å‹•åˆ©ä»˜',
        'interest_payment': 'å¹´2å›',
        'min_denomination': 10000,
        'description': 'å€‹äººå‘ã‘å›½å‚µãƒ»å¤‰å‹•é‡‘åˆ©10å¹´ç‰©',
        'is_active': True
    },
    'BOND_TANKI': {
        'bond_id': 'BOND_TANKI',
        'bond_name': 'å›½åº«çŸ­æœŸè¨¼åˆ¸',
        'bond_type': 'çŸ­æœŸå›½å‚µ',
        'maturity_years': 0.25,
        'maturity_type': 'çŸ­æœŸ',
        'issue_method': 'å‰²å¼•ç™ºè¡Œ',
        'interest_type': 'å‰²å¼•',
        'interest_payment': 'ãªã—',
        'min_denomination': 50000,
        'description': 'å›½åº«çŸ­æœŸè¨¼åˆ¸ï¼ˆå‰²å¼•çŸ­æœŸå›½å‚µï¼‰',
        'is_active': True
    },
    'BOND_BUKKA_10Y': {
        'bond_id': 'BOND_BUKKA_10Y',
        'bond_name': 'åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆç‰©ä¾¡é€£å‹•ãƒ»10å¹´ï¼‰',
        'bond_type': 'ç‰©ä¾¡é€£å‹•å›½å‚µ',
        'maturity_years': 10.0,
        'maturity_type': 'ç‰©ä¾¡é€£å‹•ãƒ»10å¹´',
        'issue_method': 'ç‰©ä¾¡é€£å‹•',
        'interest_type': 'åˆ©ä»˜',
        'interest_payment': 'å¹´2å›',
        'min_denomination': 100000,
        'description': 'ç‰©ä¾¡é€£å‹•å›½å‚µãƒ»10å¹´ç‰©',
        'is_active': True
    }
}


def get_bond_001_files(client: bigquery.Client):
    """BOND_001ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å‘Šç¤ºã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—"""
    query = f"""
    SELECT DISTINCT 
        a.announcement_id,
        a.source_file
    FROM `{PROJECT_ID}.{DATASET_ID}.announcements` a
    INNER JOIN `{PROJECT_ID}.{DATASET_ID}.bond_issuances` bi
        ON a.announcement_id = bi.announcement_id
    WHERE bi.bond_master_id = 'BOND_001'
    ORDER BY a.announcement_id
    """
    
    results = client.query(query).result()
    files = []
    for row in results:
        files.append({
            'announcement_id': row.announcement_id,
            'source_file': row.source_file
        })
    
    return files


def ensure_special_bonds_in_master(client: bigquery.Client):
    """bonds_masterã«ç‰¹æ®Šå‚µåˆ¸ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãªã‘ã‚Œã°è¿½åŠ """
    print("\nğŸ“‹ bonds_masterã«ç‰¹æ®Šå‚µåˆ¸ã‚’ç¢ºèªä¸­...")
    
    # æ—¢å­˜ã®bond_idã‚’å–å¾—
    query = f"""
    SELECT bond_id
    FROM `{PROJECT_ID}.{DATASET_ID}.{BOND_MASTER_TABLE}`
    """
    
    existing_ids = set()
    try:
        results = client.query(query).result()
        for row in results:
            existing_ids.add(row.bond_id)
    except Exception as e:
        print(f"âš ï¸ bonds_masterç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
    
    # ä¸è¶³ã—ã¦ã„ã‚‹ç‰¹æ®Šå‚µåˆ¸ã‚’è¿½åŠ 
    missing_bonds = []
    for bond_id, bond_data in SPECIAL_BOND_MASTERS.items():
        if bond_id not in existing_ids:
            missing_bonds.append(bond_data)
    
    if missing_bonds:
        print(f"ğŸ“ bonds_masterã«{len(missing_bonds)}ç¨®é¡ã®ç‰¹æ®Šå‚µåˆ¸ã‚’è¿½åŠ ã—ã¾ã™")
        for bond in missing_bonds:
            print(f"  - {bond['bond_name']}")
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
        rows = []
        for bond in missing_bonds:
            bond_copy = bond.copy()
            bond_copy['created_at'] = datetime.now().isoformat()
            bond_copy['updated_at'] = datetime.now().isoformat()
            rows.append(bond_copy)
        
        table_ref = f"{PROJECT_ID}.{DATASET_ID}.{BOND_MASTER_TABLE}"
        errors = client.insert_rows_json(table_ref, rows)
        
        if errors:
            print(f"âŒ bonds_masteræŠ•å…¥ã‚¨ãƒ©ãƒ¼:")
            for error in errors:
                print(f"  {error}")
            raise Exception("bonds_masteræŠ•å…¥å¤±æ•—")
        else:
            print(f"âœ… bonds_masterã«{len(rows)}ä»¶è¿½åŠ ã—ã¾ã—ãŸ")
    else:
        print("âœ… ç‰¹æ®Šå‚µåˆ¸ã¯ã™ã¹ã¦ç™»éŒ²æ¸ˆã¿ã§ã™")


def extract_bond_type_from_file(filepath: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‚µåˆ¸ç¨®é¡ã‚’æŠ½å‡º"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            notice_text = f.read()
        
        # ã¾ãšåˆ¥è¡¨å½¢å¼ï¼ˆè¤‡æ•°éŠ˜æŸ„ï¼‰ã§è©¦è¡Œ
        extractor = IssueExtractor(notice_text)
        issues = extractor.extract_issues()
        
        if issues and len(issues) > 0:
            # æœ€åˆã®éŠ˜æŸ„ã®ç¨®é¡ã‚’è¿”ã™
            return issues[0]['bond_type']
        
        # åˆ¥è¡¨ãŒãªã„å ´åˆã€å˜ä¸€éŠ˜æŸ„ã¨ã—ã¦è©¦è¡Œ
        print(f"  â„¹ï¸ åˆ¥è¡¨ãªã—ã€‚å˜ä¸€éŠ˜æŸ„ãƒ¢ãƒ¼ãƒ‰ã§è©¦è¡Œ...")
        table_parser = TableParser()
        bond_issuance = table_parser.extract_bond_info_from_single(notice_text)
        
        if bond_issuance:
            # BondIssuanceã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰bond_typeã‚’å–å¾—
            bond_type = bond_issuance.bond_type
            
            # ã€Œå¹´ã€ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯è¿½åŠ 
            if 'å¹´' not in bond_type:
                bond_type = f"{bond_type}å¹´"
            
            print(f"  âœ… å˜ä¸€éŠ˜æŸ„æŠ½å‡ºæˆåŠŸ: {bond_type}")
            return bond_type
        
        return None
    
    except Exception as e:
        print(f"  âŒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None


def update_bond_master_id(client: bigquery.Client, announcement_id: str, new_bond_master_id: str):
    """bond_master_idã‚’æ›´æ–°"""
    query = f"""
    UPDATE `{PROJECT_ID}.{DATASET_ID}.bond_issuances`
    SET 
        bond_master_id = @new_bond_master_id,
        updated_at = CURRENT_TIMESTAMP()
    WHERE announcement_id = @announcement_id
    """
    
    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("new_bond_master_id", "STRING", new_bond_master_id),
            bigquery.ScalarQueryParameter("announcement_id", "STRING", announcement_id)
        ]
    )
    
    client.query(query, job_config=job_config).result()


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("=" * 70)
    print("ğŸ”§ BOND_001ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆç‰¹æ®Šå‚µåˆ¸å¯¾å¿œï¼‰")
    print("=" * 70)
    
    # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    credentials_path = None  # ã¾ãŸã¯ "path/to/service-account-key.json"
    
    if credentials_path:
        credentials = service_account.Credentials.from_service_account_file(
            credentials_path,
            scopes=["https://www.googleapis.com/auth/bigquery"]
        )
        client = bigquery.Client(credentials=credentials, project=PROJECT_ID)
    else:
        client = bigquery.Client(project=PROJECT_ID)
    
    # BOND_001ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    print("\nğŸ“‹ BOND_001ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å‘Šç¤ºã‚’å–å¾—ä¸­...")
    files = get_bond_001_files(client)
    print(f"âœ… {len(files)}ä»¶ã®å‘Šç¤ºã‚’ç‰¹å®šã—ã¾ã—ãŸ")
    
    if not files:
        print("ä¿®æ­£å¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0
    
    # bonds_masterã«ç‰¹æ®Šå‚µåˆ¸ã‚’è¿½åŠ 
    ensure_special_bonds_in_master(client)
    
    # ç¢ºèª
    print(f"\nâš ï¸ {len(files)}ä»¶ã®bond_master_idã‚’æ›´æ–°ã—ã¾ã™")
    response = input("ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ")
    if response.lower() != 'yes':
        print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
        return 0
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    print("\n" + "=" * 70)
    print("ğŸš€ å‡¦ç†é–‹å§‹")
    print("=" * 70)
    
    success_count = 0
    failed_count = 0
    failed_files = []
    
    for i, file_info in enumerate(files, 1):
        announcement_id = file_info['announcement_id']
        source_file = file_info['source_file']
        
        print(f"\n[{i}/{len(files)}] {source_file}")
        print(f"  announcement_id: {announcement_id}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ï¼ˆå¹´åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
        issue_date = source_file[:8]  # YYYYMMDD
        year = int(issue_date[:4])
        month = int(issue_date[4:6])
        
        if month >= 4:
            fiscal_year = year
        else:
            fiscal_year = year - 1
        
        filepath = DATA_DIR / str(fiscal_year) / source_file
        
        if not filepath.exists():
            print(f"  âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
            failed_count += 1
            failed_files.append({'file': source_file, 'reason': 'ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹'})
            continue
        
        # å‚µåˆ¸ç¨®é¡ã‚’æŠ½å‡º
        bond_type = extract_bond_type_from_file(str(filepath))
        
        if not bond_type:
            print(f"  âš ï¸ å‚µåˆ¸ç¨®é¡ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            failed_count += 1
            failed_files.append({'file': source_file, 'reason': 'æŠ½å‡ºå¤±æ•—'})
            continue
        
        # bond_master_idã‚’å–å¾—
        bond_master_id = BOND_TYPE_TO_MASTER_ID.get(bond_type)
        
        if not bond_master_id:
            print(f"  âš ï¸ æœªçŸ¥ã®å‚µåˆ¸ç¨®é¡: {bond_type}")
            failed_count += 1
            failed_files.append({'file': source_file, 'reason': f'æœªçŸ¥ã®ç¨®é¡: {bond_type}'})
            continue
        
        print(f"  å‚µåˆ¸ç¨®é¡: {bond_type} â†’ {bond_master_id}")
        
        # BigQueryã‚’æ›´æ–°
        try:
            update_bond_master_id(client, announcement_id, bond_master_id)
            print(f"  âœ… æ›´æ–°æˆåŠŸ")
            success_count += 1
        except Exception as e:
            print(f"  âŒ æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            failed_count += 1
            failed_files.append({'file': source_file, 'reason': f'DBæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}'})
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 70)
    print("ğŸ“Š å‡¦ç†çµæœ")
    print("=" * 70)
    print(f"ç·ä»¶æ•°: {len(files)}")
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"âŒ å¤±æ•—: {failed_count}")
    
    # å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°
    if failed_files:
        print(f"\nã€å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã€‘")
        for item in failed_files:
            print(f"  - {item['file']}")
            print(f"    ç†ç”±: {item['reason']}")
    
    # æœ€çµ‚ç¢ºèª
    if success_count > 0:
        print("\n" + "=" * 70)
        print("ğŸ” æ›´æ–°å¾Œã®ç¢ºèª")
        print("=" * 70)
        
        query = f"""
        SELECT 
            bm.bond_name,
            COUNT(*) as count
        FROM `{PROJECT_ID}.{DATASET_ID}.bond_issuances` bi
        LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.{BOND_MASTER_TABLE}` bm
            ON bi.bond_master_id = bm.bond_id
        GROUP BY bm.bond_name
        ORDER BY bm.bond_name
        """
        
        results = client.query(query).result()
        print("\nã€ç¨®é¡åˆ¥é›†è¨ˆã€‘")
        for row in results:
            bond_name = row.bond_name or "ä¸æ˜"
            print(f"  {bond_name}: {row.count}ä»¶")
    
    if failed_count == 0:
        print("\nğŸ‰ ã™ã¹ã¦ã®ä¿®æ­£ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("=" * 70)
        print("Day 4 å®Œäº† ğŸŠ")
        print("=" * 70)
        return 0
    else:
        print(f"\nâš ï¸ {failed_count}ä»¶ã®ä¿®æ­£ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print("å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ã€å€‹åˆ¥ã«å¯¾å¿œã—ã¦ãã ã•ã„")
        return 1


if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)