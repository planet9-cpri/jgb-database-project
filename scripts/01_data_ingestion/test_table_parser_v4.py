"""
Phase 4 ãƒ†ã‚¹ãƒˆ: æ¨ªä¸¦ã³åˆ¥è¡¨å½¢å¼
æ·»ä»˜ã®å‘Šç¤ºï¼ˆ20230414ï¼‰ã§ãƒ†ã‚¹ãƒˆ
"""

import re
import json
from datetime import datetime
from pathlib import Path
import os
from google.cloud import bigquery

# èªè¨¼è¨­å®š
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\Users\sonke\secrets\jgb2023-f8c9b849ae2d.json'

PROJECT_ID = "jgb2023"
DATASET_ID = "20251027"


class TableParserV4:
    """æ¨ªä¸¦ã³åˆ¥è¡¨å½¢å¼ã®å‘Šç¤ºã‚’è§£æ"""
    
    def can_parse(self, text: str) -> bool:
        """ã“ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã§å‡¦ç†å¯èƒ½ã‹åˆ¤å®š"""
        if 'ï¼ˆåˆ¥è¡¨ã®ã¨ãŠã‚Šï¼‰' in text or 'å†…è¨³ï¼ˆåˆ¥è¡¨ã®ã¨ãŠã‚Šï¼‰' in text:
            if 'åç§°åŠã³è¨˜å·' in text and 'åˆ©ç‡' in text and 'å„Ÿé‚„æœŸé™' in text:
                return True
        return False
    
    def extract(self, text: str) -> dict:
        """å‘Šç¤ºã‹ã‚‰ç•ªå·ä»˜ããƒªã‚¹ãƒˆã¨åˆ¥è¡¨ã‚’æŠ½å‡º"""
        
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·ï¼ˆè¤‡æ•°éŠ˜æŸ„ï¼‰
        match = re.search(r'ï¼‘\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\nï¼’)', text, re.DOTALL)
        if match:
            bond_names = self._parse_multiple_bond_names(match.group(1))
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'bond_names': bond_names}
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹
        match = re.search(r'ï¼’\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\nï¼“)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_laws(match.group(1))
            }
        
        # é …ç›®6: ç™ºè¡Œé¡ï¼ˆåˆ¥è¡¨å‚ç…§ï¼‰
        match = re.search(r'ï¼–\s+ç™ºè¡Œé¡\s+é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if match:
            total_amount = int(match.group(1).replace(',', ''))
            items[6] = {
                'title': 'ç™ºè¡Œé¡',
                'value': f'é¡é¢é‡‘é¡ã§{match.group(1)}å††\nå†…è¨³ï¼ˆåˆ¥è¡¨ã®ã¨ãŠã‚Šï¼‰',
                'sub_number': None,
                'structured_data': {'total_amount': total_amount}
            }
        
        # é …ç›®10: ç™ºè¡Œæ—¥
        match = re.search(r'10\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\n11)', text, re.DOTALL)
        if match:
            items[10] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_date(match.group(1))
            }
        
        # åˆ¥è¡¨ã®è§£æ
        table_data = self._parse_table(text)
        if table_data:
            print(f"    [INFO] åˆ¥è¡¨ã‹ã‚‰ {len(table_data)} è¡Œã‚’æŠ½å‡º")
            # åˆ¥è¡¨ã®å„è¡Œã‚’é …ç›®6ã®ã‚µãƒ–é …ç›®ã¨ã—ã¦è¿½åŠ 
            for i, row in enumerate(table_data, start=1):
                items[f'6_{i}'] = {
                    'title': 'ç™ºè¡Œé¡ï¼ˆåˆ¥è¡¨ï¼‰',
                    'value': self._format_table_row(row),
                    'sub_number': i,
                    'structured_data': row
                }
        
        return items
    
    def _parse_multiple_bond_names(self, text: str) -> list:
        """è¤‡æ•°ã®éŠ˜æŸ„åã‚’æŠ½å‡º"""
        bond_names = []
        parts = re.split(r'åŠã³', text)
        
        for part in parts:
            part = part.strip()
            if 'åˆ©ä»˜å›½åº«å‚µåˆ¸' in part:
                bond_names.append(part)
        
        return bond_names
    
    def _parse_laws(self, text: str) -> dict:
        """æ³•ä»¤ã‚’æŠ½å‡º"""
        laws = []
        
        text_normalized = text.replace('ï¼”', '4').replace('ï¼–', '6').replace('ï¼’', '2').replace('ï¼‘', '1')
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬62æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬62æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …',
                'amount': 0
            })
        
        print(f"    [DEBUG] æ³•ä»¤ã‚’ {len(laws)} ä»¶æŠ½å‡º")
        for law in laws:
            print(f"    [DEBUG]   - {law['key']}")
        
        return {'laws': laws}
    
    def _parse_date(self, text: str) -> dict:
        """ç™ºè¡Œæ—¥ã‚’è§£æ"""
        match = re.search(r'ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥', text)
        if match:
            year = int(match.group(1)) + 2018
            month = int(match.group(2))
            day = int(match.group(3))
            return {'issue_date': f'{year}-{month:02d}-{day:02d}'}
        return {'raw': text}
    
    def _parse_table(self, text: str) -> list:
        """åˆ¥è¡¨ã‚’è§£æ"""
        
        table_start = text.find('ï¼ˆåˆ¥è¡¨ï¼‰')
        if table_start == -1:
            return []
        
        table_text = text[table_start:]
        
        rows = []
        
        pattern = r'åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆ(.+?)ï¼‰ï¼ˆç¬¬(\d+)å›ï¼‰\s+([\d.]+)ï¼…\s+ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥\s+ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬(\d+)æ¡ç¬¬ï¼‘é …åˆ†\s+([\d,]+)å††'
        
        matches = re.finditer(pattern, table_text)
        
        for match in matches:
            bond_type = match.group(1)
            series = match.group(2)
            rate = float(match.group(3))
            maturity_year = int(match.group(4)) + 2018
            maturity_month = int(match.group(5))
            maturity_day = int(match.group(6))
            law_article = match.group(7)
            amount = int(match.group(8).replace(',', ''))
            
            law_key = f'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬{law_article}æ¡ç¬¬1é …'
            
            row = {
                'bond_name': f'åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆ{bond_type}ï¼‰',
                'bond_series': f'ç¬¬{series}å›',
                'interest_rate': rate,
                'maturity_date': f'{maturity_year}-{maturity_month:02d}-{maturity_day:02d}',
                'law_key': law_key,
                'law_article': f'ç¬¬{law_article}æ¡ç¬¬1é …',
                'issue_amount': amount
            }
            
            rows.append(row)
        
        return rows
    
    def _format_table_row(self, row: dict) -> str:
        """è¡¨ã®è¡Œã‚’æ–‡å­—åˆ—ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return (f"{row['bond_name']}{row['bond_series']}: "
                f"åˆ©ç‡{row['interest_rate']}%, "
                f"å„Ÿé‚„æœŸé™{row['maturity_date']}, "
                f"{row['law_key']}, "
                f"ç™ºè¡Œé¡{row['issue_amount']:,}å††")


def insert_to_bigquery(announcement_id: str, raw_text: str, items: dict, file_path: Path):
    """BigQueryã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥"""
    
    client = bigquery.Client(project=PROJECT_ID)
    
    issue_date = items.get(10, {}).get('structured_data', {}).get('issue_date', '2023-04-14')
    announcement_date = '2023-05-09'
    announcement_number = 'ç¬¬ç™¾äºŒåä¸ƒå·'
    
    # Layer 1: raw_announcements
    raw_row = {
        'announcement_id': announcement_id,
        'announcement_date': announcement_date,
        'announcement_number': announcement_number,
        'issue_date': issue_date,
        'format_pattern': 'TABLE_HORIZONTAL',
        'format_pattern_confidence': 1.0,
        'raw_text': raw_text,
        'source_file': file_path.name,
        'file_path': str(file_path),
        'parsed': True,
        'parse_error': None,
        'parsed_at': datetime.now().isoformat()
    }
    
    table_ref = f"{PROJECT_ID}.{DATASET_ID}.raw_announcements"
    errors = client.insert_rows_json(table_ref, [raw_row])
    
    if errors:
        print(f"âŒ Layer 1 æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
        return False
    else:
        print(f"âœ… Layer 1 æŠ•å…¥æˆåŠŸ: {announcement_id}")
    
    # Layer 2: announcement_items
    item_rows = []
    for key, item_data in items.items():
        if isinstance(key, str) and '_' in key:
            parts = key.split('_')
            item_number = int(parts[0])
            sub_number = int(parts[1])
        else:
            item_number = int(key)
            sub_number = item_data.get('sub_number')
        
        item_row = {
            'item_id': f"{announcement_id}_item{key}",
            'announcement_id': announcement_id,
            'item_number': item_number,
            'sub_number': sub_number,
            'item_title': item_data['title'],
            'item_value': item_data['value'],
            'structured_data': json.dumps(item_data['structured_data'], ensure_ascii=False)
        }
        item_rows.append(item_row)
    
    table_ref = f"{PROJECT_ID}.{DATASET_ID}.announcement_items"
    errors = client.insert_rows_json(table_ref, item_rows)
    
    if errors:
        print(f"âŒ Layer 2 æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
        return False
    else:
        print(f"âœ… Layer 2 æŠ•å…¥æˆåŠŸ: {len(item_rows)} é …ç›®")
    
    return True


def test_table_parser():
    """æ¨ªä¸¦ã³åˆ¥è¡¨å½¢å¼ã®ãƒ†ã‚¹ãƒˆ"""
    
    file_path = Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20230414_ä»¤å’Œ5å¹´5æœˆ9æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬ç™¾äºŒåä¸ƒå·ï¼‰.txt")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        text = f.read()
    
    print("=" * 70)
    print("Phase 4 ãƒ†ã‚¹ãƒˆ: æ¨ªä¸¦ã³åˆ¥è¡¨å½¢å¼")
    print("=" * 70)
    print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«: {file_path.name}")
    print(f"ğŸ“ æ–‡å­—æ•°: {len(text):,}")
    print()
    
    # ãƒ‘ãƒ¼ã‚µãƒ¼åˆ¤å®š
    parser = TableParserV4()
    if not parser.can_parse(text):
        print("âŒ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ¨ªä¸¦ã³åˆ¥è¡¨å½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        return
    
    print("âœ… æ¨ªä¸¦ã³åˆ¥è¡¨å½¢å¼ã‚’æ¤œå‡º")
    print()
    
    # ãƒ‘ãƒ¼ã‚¹å®Ÿè¡Œ
    items = parser.extract(text)
    
    print(f"âœ… ãƒ‘ãƒ¼ã‚¹å®Œäº†: {len(items)} é …ç›®æŠ½å‡º")
    print()
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("-" * 70)
    print("ğŸ“Š æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼")
    print("-" * 70)
    
    if 1 in items:
        bond_names = items[1]['structured_data'].get('bond_names', [])
        print(f"éŠ˜æŸ„æ•°: {len(bond_names)}")
        print(f"ä¾‹: {bond_names[0] if bond_names else 'N/A'}")
    
    if 6 in items:
        total_amount = items[6]['structured_data'].get('total_amount', 0)
        print(f"ç·ç™ºè¡Œé¡: {total_amount:,}å††ï¼ˆ{total_amount/1_000_000_000_000:.2f}å…†å††ï¼‰")
    
    if 10 in items:
        print(f"ç™ºè¡Œæ—¥: {items[10]['structured_data'].get('issue_date', 'N/A')}")
    
    # åˆ¥è¡¨ã®è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    table_rows = [k for k in items.keys() if isinstance(k, str) and k.startswith('6_')]
    print(f"åˆ¥è¡¨ã®è¡Œæ•°: {len(table_rows)}")
    
    print()
    
    # æ ¹æ‹ æ³•ä»¤åˆ¥ã®ç™ºè¡Œé¡ã‚’é›†è¨ˆ
    if 2 in items and len(table_rows) > 0:
        print("-" * 70)
        print("ğŸ’° æ ¹æ‹ æ³•ä»¤åˆ¥ã®ç™ºè¡Œé¡é›†è¨ˆï¼ˆåˆ¥è¡¨ã‹ã‚‰ï¼‰")
        print("-" * 70)
        
        law_totals = {}
        
        for key in table_rows:
            row_data = items[key]['structured_data']
            law_key = row_data.get('law_key')
            amount = row_data.get('issue_amount', 0)
            
            if law_key:
                law_totals[law_key] = law_totals.get(law_key, 0) + amount
        
        print(f"\n{'æ³•ä»¤':<55} {'ç™ºè¡Œé¡ï¼ˆå††ï¼‰':>20} {'å…†å††':>10}")
        print("-" * 90)
        
        total = 0
        for law_key, amount in sorted(law_totals.items(), key=lambda x: x[1], reverse=True):
            trillion = amount / 1_000_000_000_000
            print(f"{law_key:<55} {amount:>20,} {trillion:>9.2f}")
            total += amount
        
        print("-" * 90)
        print(f"{'åˆè¨ˆ':<55} {total:>20,} {total/1_000_000_000_000:>9.2f}")
        print()
    
    # BigQueryã¸æŠ•å…¥
    print("-" * 70)
    print("ğŸ“¤ BigQuery ã¸ãƒ‡ãƒ¼ã‚¿æŠ•å…¥")
    print("-" * 70)
    
    announcement_id = "20230414_127"
    success = insert_to_bigquery(announcement_id, text, items, file_path)
    
    if success:
        print()
        print("=" * 70)
        print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        print("=" * 70)
        print(f"Announcement ID: {announcement_id}")
        print(f"Layer 1: raw_announcements ã« 1è¡Œ æŠ•å…¥")
        print(f"Layer 2: announcement_items ã« {len(items)}è¡Œ æŠ•å…¥")
        print()
        print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: BigQueryã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
    else:
        print()
        print("âŒ ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    return items


if __name__ == "__main__":
    test_table_parser()