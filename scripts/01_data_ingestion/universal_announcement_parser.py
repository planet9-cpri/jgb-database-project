"""
Phase 4 çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼: Universal Announcement Parser
4ã¤ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’çµ±åˆã—ã€è‡ªå‹•åˆ¤å®šæ©Ÿèƒ½ã‚’å®Ÿè£…
"""

import re
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional
import os
from google.cloud import bigquery

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\Users\sonke\secrets\jgb2023-f8c9b849ae2d.json'

PROJECT_ID = "jgb2023"
DATASET_ID = "20251027"


# æ—¢å­˜ã®4ã¤ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆç°¡ç•¥ç‰ˆã‚’ã“ã“ã«å«ã‚ã‚‹ï¼‰
class NumberedListParser:
    """ç•ªå·ä»˜ããƒªã‚¹ãƒˆå½¢å¼ï¼ˆè¤‡æ•°æ³•ä»¤ï¼‰"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰"""
        score = 0.0
        
        # ä¾¡æ ¼ç«¶äº‰å…¥æœ­ + éä¾¡æ ¼ç«¶äº‰å…¥æœ­
        if 'ä¾¡æ ¼ç«¶äº‰å…¥æœ­' in text and 'éä¾¡æ ¼ç«¶äº‰å…¥æœ­' in text:
            score += 0.5
        
        # è¤‡æ•°æ³•ä»¤ï¼ˆä¸¦ã³ã«ã€åŠã³ï¼‰
        if 'ä¸¦ã³ã«' in text and 'åŠã³' in text:
            score += 0.3
        
        # åˆ¥è¡¨ãªã—
        if 'åˆ¥è¡¨' not in text:
            score += 0.2
        
        return min(score, 1.0)
    
    def extract(self, text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆç°¡ç•¥ç‰ˆï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã¯ prototype_v4_parser.py ã‚’å‚ç…§
        return {'pattern': 'NUMBERED_LIST_MULTI_LAW', 'items': {}}


class TableParserV4:
    """æ¨ªä¸¦ã³åˆ¥è¡¨å½¢å¼"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰"""
        score = 0.0
        
        # åˆ¥è¡¨ã®å­˜åœ¨
        if 'ï¼ˆåˆ¥è¡¨ã®ã¨ãŠã‚Šï¼‰' in text or 'å†…è¨³ï¼ˆåˆ¥è¡¨ã®ã¨ãŠã‚Šï¼‰' in text:
            score += 0.4
        
        # åˆ¥è¡¨ã®å®Ÿãƒ‡ãƒ¼ã‚¿
        if 'åç§°åŠã³è¨˜å·' in text and 'åˆ©ç‡' in text and 'å„Ÿé‚„æœŸé™' in text:
            score += 0.6
        
        return min(score, 1.0)
    
    def extract(self, text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆç°¡ç•¥ç‰ˆï¼‰"""
        return {'pattern': 'TABLE_HORIZONTAL', 'items': {}}


class RetailBondParser:
    """å€‹äººå‘ã‘å›½å‚µ"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰"""
        if 'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸' in text or 'å€‹äººå‘ã‘å›½å‚µ' in text:
            return 1.0
        return 0.0
    
    def extract(self, text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆç°¡ç•¥ç‰ˆï¼‰"""
        return {'pattern': 'RETAIL_BOND', 'items': {}}


class TBParser:
    """å›½åº«çŸ­æœŸè¨¼åˆ¸"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰"""
        score = 0.0
        
        if 'å›½åº«çŸ­æœŸè¨¼åˆ¸' in text:
            score += 0.5
        
        if 'å‰²å¼•çŸ­æœŸå›½å‚µ' in text or 'æ”¿åºœçŸ­æœŸè¨¼åˆ¸' in text:
            score += 0.5
        
        return min(score, 1.0)
    
    def extract(self, text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆç°¡ç•¥ç‰ˆï¼‰"""
        return {'pattern': 'TB_SHORT_TERM', 'items': {}}


class UniversalAnnouncementParser:
    """çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ï¼šã™ã¹ã¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œ"""
    
    def __init__(self):
        # 4ã¤ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ç™»éŒ²ï¼ˆå„ªå…ˆé †ä½é †ï¼‰
        self.parsers = [
            ('RETAIL_BOND', RetailBondParser()),
            ('TB_SHORT_TERM', TBParser()),
            ('TABLE_HORIZONTAL', TableParserV4()),
            ('NUMBERED_LIST_MULTI_LAW', NumberedListParser()),
        ]
    
    def identify_pattern(self, text: str) -> tuple[str, float]:
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•è­˜åˆ¥
        
        Returns:
            (pattern_name, confidence_score)
        """
        scores = {}
        
        for pattern_name, parser in self.parsers:
            score = parser.can_parse(text)
            scores[pattern_name] = score
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
        best_pattern = max(scores.items(), key=lambda x: x[1])
        
        return best_pattern[0], best_pattern[1]
    
    def parse(self, text: str) -> Dict[str, Any]:
        """
        å‘Šç¤ºã‚’è§£æ
        
        Returns:
            {
                'pattern': ãƒ‘ã‚¿ãƒ¼ãƒ³å,
                'confidence': ä¿¡é ¼åº¦,
                'items': æŠ½å‡ºãƒ‡ãƒ¼ã‚¿,
                'error': ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚ã‚Œã°ï¼‰
            }
        """
        try:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥
            pattern, confidence = self.identify_pattern(text)
            
            # ä¿¡é ¼åº¦ãŒä½ã™ãã‚‹å ´åˆã¯è­¦å‘Š
            if confidence < 0.5:
                return {
                    'pattern': 'UNKNOWN',
                    'confidence': confidence,
                    'items': {},
                    'error': f'ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥ã®ä¿¡é ¼åº¦ãŒä½ã„ï¼ˆ{confidence:.2f}ï¼‰'
                }
            
            # é©åˆ‡ãªãƒ‘ãƒ¼ã‚µãƒ¼ã‚’é¸æŠ
            parser = None
            for p_name, p in self.parsers:
                if p_name == pattern:
                    parser = p
                    break
            
            if parser is None:
                return {
                    'pattern': pattern,
                    'confidence': confidence,
                    'items': {},
                    'error': f'ãƒ‘ãƒ¼ã‚µãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}'
                }
            
            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            items = parser.extract(text)
            
            return {
                'pattern': pattern,
                'confidence': confidence,
                'items': items.get('items', {}),
                'error': None
            }
        
        except Exception as e:
            return {
                'pattern': 'ERROR',
                'confidence': 0.0,
                'items': {},
                'error': str(e)
            }


def batch_process(
    input_dir: Path,
    dataset_id: str = DATASET_ID,
    test_mode: bool = True,
    max_files: int = 10
) -> Dict[str, Any]:
    """
    ãƒãƒƒãƒå‡¦ç†ï¼šè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†
    
    Args:
        input_dir: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        dataset_id: BigQueryãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆID
        test_mode: ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆTrueã§æœ€å¤§max_filesä»¶ï¼‰
        max_files: ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰æ™‚ã®æœ€å¤§å‡¦ç†ä»¶æ•°
    
    Returns:
        å‡¦ç†çµæœã®çµ±è¨ˆæƒ…å ±
    """
    parser = UniversalAnnouncementParser()
    client = bigquery.Client(project=PROJECT_ID)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
    files = sorted(input_dir.glob('*.txt'))
    
    if test_mode:
        files = files[:max_files]
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®{len(files)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
    else:
        print(f"ğŸš€ æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰: {len(files)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
    
    print()
    
    # çµ±è¨ˆæƒ…å ±
    stats = {
        'total': len(files),
        'success': 0,
        'failed': 0,
        'by_pattern': {},
        'errors': []
    }
    
    for i, file_path in enumerate(files, 1):
        print(f"[{i}/{len(files)}] {file_path.name}")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            # ãƒ‘ãƒ¼ã‚¹
            result = parser.parse(text)
            
            pattern = result['pattern']
            confidence = result['confidence']
            
            print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern} (ä¿¡é ¼åº¦: {confidence:.2f})")
            
            # çµ±è¨ˆæ›´æ–°
            if pattern not in stats['by_pattern']:
                stats['by_pattern'][pattern] = 0
            stats['by_pattern'][pattern] += 1
            
            if result['error']:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
                stats['failed'] += 1
                stats['errors'].append({
                    'file': file_path.name,
                    'pattern': pattern,
                    'error': result['error']
                })
            else:
                print(f"  âœ… æˆåŠŸ")
                stats['success'] += 1
            
            print()
        
        except Exception as e:
            print(f"  âŒ ä¾‹å¤–: {e}")
            stats['failed'] += 1
            stats['errors'].append({
                'file': file_path.name,
                'pattern': 'EXCEPTION',
                'error': str(e)
            })
            print()
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("=" * 70)
    print("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    print(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total']}")
    print(f"æˆåŠŸ: {stats['success']} ({stats['success']/stats['total']*100:.1f}%)")
    print(f"å¤±æ•—: {stats['failed']} ({stats['failed']/stats['total']*100:.1f}%)")
    print()
    
    print("ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥:")
    for pattern, count in sorted(stats['by_pattern'].items(), key=lambda x: x[1], reverse=True):
        print(f"  {pattern}: {count} ({count/stats['total']*100:.1f}%)")
    print()
    
    if stats['errors']:
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°ï¼ˆæœ€åˆã®5ä»¶ï¼‰:")
        for error in stats['errors'][:5]:
            print(f"  - {error['file']}: {error['error'][:50]}...")
        print()
    
    return stats


def test_universal_parser():
    """çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    
    print("=" * 70)
    print("Phase 4 çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    print()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_files = [
        Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20230915_ä»¤å’Œ5å¹´10æœˆ11æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬äºŒç™¾äº”åä¸€å·ï¼‰.txt"),
        Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20230414_ä»¤å’Œ5å¹´5æœˆ9æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬ç™¾äºŒåä¸ƒå·ï¼‰.txt"),
        Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20230615_ä»¤å’Œ5å¹´7æœˆ11æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬ç™¾ä¹åäºŒå·ï¼‰.txt"),
        Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20231211_ä»¤å’Œ6å¹´1æœˆ12æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬åå…­å·ï¼‰.txt"),
    ]
    
    parser = UniversalAnnouncementParser()
    
    for file_path in test_files:
        if not file_path.exists():
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path.name}")
            continue
        
        print(f"ğŸ“„ {file_path.name}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
        
        result = parser.parse(text)
        
        print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³: {result['pattern']}")
        print(f"  ä¿¡é ¼åº¦: {result['confidence']:.2f}")
        
        if result['error']:
            print(f"  ã‚¨ãƒ©ãƒ¼: {result['error']}")
        else:
            print(f"  âœ… ãƒ‘ãƒ¼ã‚¹æˆåŠŸ")
        
        print()
    
    print("=" * 70)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 70)


if __name__ == "__main__":
    # çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ã®ãƒ†ã‚¹ãƒˆ
    test_universal_parser()
    
    print()
    print("=" * 70)
    print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. batch_process() ã§ãƒãƒƒãƒå‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ")
    print("  2. å®Ÿéš›ã®ãƒ‘ãƒ¼ã‚µãƒ¼å®Ÿè£…ã‚’çµ±åˆ")
    print("  3. å…¨ä»¶å‡¦ç†ï¼ˆ179ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
    print("=" * 70)