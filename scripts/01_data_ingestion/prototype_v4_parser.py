"""
Phase 4 Prototype: Universal Parser v4
æ·»ä»˜ã®å‘Šç¤ºï¼ˆ20230915ï¼‰ã§ãƒ†ã‚¹ãƒˆ

3å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥ï¼š
- Layer 1: raw_announcementsï¼ˆå‘Šç¤ºãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
- Layer 2: announcement_itemsï¼ˆæ­£è¦åŒ–ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
- Layer 3: ãƒ“ãƒ¥ãƒ¼ï¼ˆå¾Œã§ä½œæˆï¼‰
"""

import re
import json
from datetime import datetime
from pathlib import Path
import os
from google.cloud import bigquery

# èªè¨¼è¨­å®š
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\Users\sonke\secrets\jgb2023-f8c9b849ae2d.json'

PROJECT_ID = "jgb2023"
DATASET_ID = "20251027"


class NumberedListExtractor:
    """ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆ1ï½20ï¼‰ã‚’æŠ½å‡º"""
    
    def extract(self, text: str) -> dict:
        """å‘Šç¤ºã‹ã‚‰ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚’æŠ½å‡º"""
        
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·
        match = re.search(r'ï¼‘\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\nï¼’)', text, re.DOTALL)
        if match:
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item1(match.group(1))
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …
        match = re.search(r'ï¼’\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\nï¼“)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item2(match.group(1))
            }
        
        # é …ç›®6: ç™ºè¡Œé¡ï¼ˆè¤‡é›‘ãªã®ã§è©³ç´°ã«ï¼‰
        match = re.search(r'ï¼–\s+ç™ºè¡Œé¡(.+?)(?=\nï¼—)', text, re.DOTALL)
        if match:
            full_text = match.group(1).strip()
            items[6] = {
                'title': 'ç™ºè¡Œé¡',
                'value': full_text,
                'sub_number': None,
                'structured_data': self._parse_item6(full_text)
            }
            
            # ã‚µãƒ–é …ç›®ã‚‚æŠ½å‡ºï¼ˆâ‘´â‘µâ‘¶ï¼‰
            sub_items = self._extract_sub_items(full_text)
            for sub_num, sub_data in sub_items.items():
                items[f'6_{sub_num}'] = {
                    'title': f'ç™ºè¡Œé¡â‘´â‘µâ‘¶',
                    'value': sub_data['value'],
                    'sub_number': sub_num,
                    'structured_data': sub_data['structured']
                }
        
        # é …ç›®10: ç™ºè¡Œæ—¥
        match = re.search(r'10\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\n11)', text, re.DOTALL)
        if match:
            items[10] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item10(match.group(1))
            }
        
        # é …ç›®12: åˆ©ç‡
        match = re.search(r'12\s+åˆ©ç‡\s+(.+?)(?=\n13)', text, re.DOTALL)
        if match:
            items[12] = {
                'title': 'åˆ©ç‡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item12(match.group(1))
            }
        
        # é …ç›®16: å„Ÿé‚„æœŸé™
        match = re.search(r'16\s+å„Ÿé‚„æœŸé™\s+(.+?)(?=\n17)', text, re.DOTALL)
        if match:
            items[16] = {
                'title': 'å„Ÿé‚„æœŸé™',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item16(match.group(1))
            }
        
        # é …ç›®17: å„Ÿé‚„é‡‘é¡
        match = re.search(r'17\s+å„Ÿé‚„é‡‘é¡\s+(.+?)(?=\n18)', text, re.DOTALL)
        if match:
            items[17] = {
                'title': 'å„Ÿé‚„é‡‘é¡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item17(match.group(1))
            }
        
        return items
    
    def _extract_sub_items(self, text: str) -> dict:
        """â‘´â‘µâ‘¶ã®ã‚µãƒ–é …ç›®ã‚’æŠ½å‡º"""
        sub_items = {}
        
        # â‘´ã‚’æŠ½å‡º
        match1 = re.search(r'â‘´\s*ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)(?=â‘µ|$)', text, re.DOTALL)
        if match1:
            sub_items[1] = {
                'value': f'â‘´ ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match1.group(1).strip()}',
                'structured': self._parse_sub_item_amount(match1.group(1))
            }
        
        # â‘µã‚’æŠ½å‡º
        match2 = re.search(r'â‘µ\s*å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â… éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)(?=â‘¶|$)', text, re.DOTALL)
        if match2:
            sub_items[2] = {
                'value': f'â‘µ å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â… éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match2.group(1).strip()}',
                'structured': self._parse_sub_item_amount(match2.group(1))
            }
        
        # â‘¶ã‚’æŠ½å‡º
        match3 = re.search(r'â‘¶\s*å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â…¡éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)$', text, re.DOTALL)
        if match3:
            sub_items[3] = {
                'value': f'â‘¶ å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â…¡éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match3.group(1).strip()}',
                'structured': self._parse_sub_item_amount(match3.group(1))
            }
        
        return sub_items
    
    def _parse_sub_item_amount(self, text: str) -> dict:
        """ã‚µãƒ–é …ç›®ã‹ã‚‰ç™ºè¡Œé¡ã‚’æŠ½å‡ºï¼ˆã€ŒåŒæ³•ã€å¯¾å¿œç‰ˆï¼‰"""
        result = {'total_amount': 0, 'by_law': {}}
        
        # ç·é¡ã‚’æŠ½å‡º
        total_match = re.search(r'é¡é¢é‡‘é¡ã§([\d,]+)å††', text)
        if total_match:
            result['total_amount'] = int(total_match.group(1).replace(',', ''))
        
        # æ³•ä»¤åˆ¥ã®å†…è¨³
        last_law_name = None
        
        # æ˜ç¤ºçš„ãªæ³•ä»¤åã®ãƒãƒƒãƒ
        law_matches = re.finditer(
            r'([^ã€]+ç¬¬\d+æ¡ç¬¬\d+é …)ã®è¦å®šã«åŸºã¥ã.*?é¡é¢é‡‘é¡ã§([\d,]+)å††',
            text
        )
        
        for match in law_matches:
            law_ref = match.group(1).strip()
            amount = int(match.group(2).replace(',', ''))
            
            # æ³•å¾‹åã‚’æ­£è¦åŒ–
            law_key = self._normalize_law_name(law_ref)
            if law_key:
                result['by_law'][law_key] = amount
                
                # æ³•å¾‹åã‚’è¨˜æ†¶
                if 'ç‰¹åˆ¥ä¼šè¨ˆ' in law_ref:
                    last_law_name = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿é‹å–¶' in law_ref:
                    last_law_name = 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿æ³•' in law_ref:
                    last_law_name = 'è²¡æ”¿æ³•'
        
        # ã€ŒåŒæ³•ç¬¬â—‹æ¡ç¬¬â—‹é …ã€ã®ãƒãƒƒãƒ
        same_law_matches = re.finditer(
            r'åŒæ³•ç¬¬(\d+)æ¡ç¬¬(\d+)é …ã®è¦å®šã«åŸºã¥ã.*?é¡é¢é‡‘é¡ã§([\d,]+)å††',
            text
        )
        
        for match in same_law_matches:
            article = match.group(1)
            paragraph = match.group(2)
            amount = int(match.group(3).replace(',', ''))
            
            if last_law_name:
                if last_law_name == 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹':
                    if article == '46':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'
                    elif article == '62':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …'
                    else:
                        law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                elif last_law_name == 'è²¡æ”¿æ³•':
                    law_key = f'è²¡æ”¿æ³•ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                elif last_law_name == 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹':
                    law_key = f'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                else:
                    law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                
                result['by_law'][law_key] = amount
        
        return result
    
    def _normalize_law_name(self, law_ref: str) -> str:
        """æ³•å¾‹åã‚’æ­£è¦åŒ–"""
        if 'è²¡æ”¿æ³•' in law_ref and 'ç¬¬ï¼”æ¡' in law_ref:
            return 'è²¡æ”¿æ³•ç¬¬4æ¡ç¬¬1é …'
        elif 'è²¡æ”¿é‹å–¶' in law_ref:
            return 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬3æ¡ç¬¬1é …'
        elif 'ç‰¹åˆ¥ä¼šè¨ˆ' in law_ref:
            if 'ç¬¬46æ¡' in law_ref:
                return 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'
            elif 'ç¬¬62æ¡' in law_ref:
                return 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …'
        return None
    
    def _parse_item1(self, text: str) -> dict:
        """é …ç›®1: åç§°åŠã³è¨˜å·ã‚’æ§‹é€ åŒ–"""
        match = re.search(r'åˆ©\s*ä»˜å›½åº«å‚µåˆ¸[ï¼ˆ\(](.+?)[ï¼‰\)][ï¼ˆ\(]ç¬¬(\d+)å›[ï¼‰\)]', text)
        if match:
            return {
                'bond_name': f'åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆ{match.group(1)}ï¼‰',
                'bond_series': f'ç¬¬{match.group(2)}å›'
            }
        return {'raw': text}
    
    def _parse_item2(self, text: str) -> dict:
        """é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹ã‚’æ§‹é€ åŒ–ï¼ˆæ”¹å–„ç‰ˆ + ãƒ‡ãƒãƒƒã‚°ï¼‰"""
        
        laws = []
        
        # å…¨è§’æ•°å­—ã‚’åŠè§’ã«å¤‰æ›
        text_normalized = text.replace('ï¼”', '4').replace('ï¼“', '3').replace('ï¼‘', '1')
        
        print(f"    [DEBUG] é …ç›®2ã®å…ƒãƒ†ã‚­ã‚¹ãƒˆ: {text[:100]}...")
        print(f"    [DEBUG] æ­£è¦åŒ–å¾Œ: {text_normalized[:100]}...")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: è²¡æ”¿æ³•
        if re.search(r'è²¡æ”¿æ³•.*?ç¬¬4æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            print("    [DEBUG] âœ… è²¡æ”¿æ³•ã‚’æ¤œå‡º")
            laws.append({
                'name': 'è²¡æ”¿æ³•',
                'full_name': 'è²¡æ”¿æ³•ï¼ˆæ˜­å’Œ22å¹´æ³•å¾‹ç¬¬34å·ï¼‰',
                'article': 'ç¬¬4æ¡ç¬¬1é …',
                'key': 'è²¡æ”¿æ³•ç¬¬4æ¡ç¬¬1é …',
                'amount': 0
            })
        else:
            print("    [DEBUG] âŒ è²¡æ”¿æ³•ã‚’æ¤œå‡ºã§ããš")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: è²¡æ”¿é‹å–¶ï¼ˆå…¬å‚µç‰¹ä¾‹æ³•ï¼‰
        if re.search(r'è²¡æ”¿é‹å–¶.*?ç¬¬3æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            print("    [DEBUG] âœ… è²¡æ”¿é‹å–¶æ³•ã‚’æ¤œå‡º")
            laws.append({
                'name': 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ24å¹´æ³•å¾‹ç¬¬101å·ï¼‰',
                'article': 'ç¬¬3æ¡ç¬¬1é …',
                'key': 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬3æ¡ç¬¬1é …',
                'amount': 0
            })
        else:
            print("    [DEBUG] âŒ è²¡æ”¿é‹å–¶æ³•ã‚’æ¤œå‡ºã§ããš")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬46æ¡
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            print("    [DEBUG] âœ… ç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬46æ¡ã‚’æ¤œå‡º")
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        else:
            print("    [DEBUG] âŒ ç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬46æ¡ã‚’æ¤œå‡ºã§ããš")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³4: ç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬62æ¡
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬62æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            print("    [DEBUG] âœ… ç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬62æ¡ã‚’æ¤œå‡º")
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬62æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …',
                'amount': 0
            })
        else:
            print("    [DEBUG] âŒ ç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬62æ¡ã‚’æ¤œå‡ºã§ããš")
        
        print(f"    [DEBUG] æœ€çµ‚çš„ã«æŠ½å‡ºã•ã‚ŒãŸæ³•ä»¤æ•°: {len(laws)}")
        
        return {'laws': laws}
    
    def _parse_item6(self, text: str) -> dict:
        """é …ç›®6: ç™ºè¡Œé¡ã‚’æ§‹é€ åŒ–"""
        
        result = {
            'total_amount': 0,
            'competitive': {'amount': 0, 'by_law': {}},
            'noncompetitive1': {'amount': 0, 'by_law': {}},
            'noncompetitive2': {'amount': 0, 'by_law': {}}
        }
        
        # â‘´ ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ
        comp_match = re.search(r'â‘´\s*ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ\s*é¡é¢é‡‘é¡ã§([\d,]+)å††', text)
        if comp_match:
            amount = int(comp_match.group(1).replace(',', ''))
            result['competitive']['amount'] = amount
            result['total_amount'] += amount
            
            # æ³•ä»¤åˆ¥ã®å†…è¨³
            comp_section = re.search(r'â‘´(.+?)(?=â‘µ|$)', text, re.DOTALL)
            if comp_section:
                result['competitive']['by_law'] = self._extract_law_amounts_from_section(comp_section.group(1))
        
        # â‘µ ç¬¬â… éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ
        nc1_match = re.search(r'â‘µ.*?é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if nc1_match:
            amount = int(nc1_match.group(1).replace(',', ''))
            result['noncompetitive1']['amount'] = amount
            result['total_amount'] += amount
            
            nc1_section = re.search(r'â‘µ(.+?)(?=â‘¶|$)', text, re.DOTALL)
            if nc1_section:
                result['noncompetitive1']['by_law'] = self._extract_law_amounts_from_section(nc1_section.group(1))
        
        # â‘¶ ç¬¬â…¡éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ
        nc2_match = re.search(r'â‘¶.*?é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if nc2_match:
            amount = int(nc2_match.group(1).replace(',', ''))
            result['noncompetitive2']['amount'] = amount
            result['total_amount'] += amount
            
            nc2_section = re.search(r'â‘¶(.+?)$', text, re.DOTALL)
            if nc2_section:
                result['noncompetitive2']['by_law'] = self._extract_law_amounts_from_section(nc2_section.group(1))
        
        return result
    
    def _extract_law_amounts_from_section(self, section: str) -> dict:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æ³•ä»¤åˆ¥ã®ç™ºè¡Œé¡ã‚’æŠ½å‡ºï¼ˆã€ŒåŒæ³•ã€å¯¾å¿œç‰ˆï¼‰"""
        by_law = {}
        
        # ã¾ãšã€æ˜ç¤ºçš„ãªæ³•ä»¤åã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒãƒƒãƒ
        law_matches = re.finditer(
            r'([^ã€]+ç¬¬\d+æ¡ç¬¬\d+é …)ã®è¦å®šã«åŸºã¥ã.*?é¡é¢é‡‘é¡ã§([\d,]+)å††',
            section
        )
        
        last_law_name = None  # ç›´å‰ã®æ³•å¾‹åã‚’è¨˜æ†¶
        
        for match in law_matches:
            law_ref = match.group(1).strip()
            amount = int(match.group(2).replace(',', ''))
            
            # æ³•å¾‹åã‚’æ­£è¦åŒ–
            law_key = self._normalize_law_name(law_ref)
            if law_key:
                by_law[law_key] = amount
                
                # æ³•å¾‹åã‚’è¨˜æ†¶ï¼ˆã€ŒåŒæ³•ã€ç”¨ï¼‰
                if 'ç‰¹åˆ¥ä¼šè¨ˆ' in law_ref:
                    last_law_name = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿é‹å–¶' in law_ref:
                    last_law_name = 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿æ³•' in law_ref:
                    last_law_name = 'è²¡æ”¿æ³•'
        
        # ã€ŒåŒæ³•ç¬¬â—‹æ¡ç¬¬â—‹é …ã€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒãƒƒãƒ
        same_law_matches = re.finditer(
            r'åŒæ³•ç¬¬(\d+)æ¡ç¬¬(\d+)é …ã®è¦å®šã«åŸºã¥ã.*?é¡é¢é‡‘é¡ã§([\d,]+)å††',
            section
        )
        
        for match in same_law_matches:
            article = match.group(1)
            paragraph = match.group(2)
            amount = int(match.group(3).replace(',', ''))
            
            # ç›´å‰ã®æ³•å¾‹åã‚’ä½¿ç”¨
            if last_law_name:
                if last_law_name == 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹':
                    if article == '46':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'
                    elif article == '62':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …'
                    else:
                        law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                elif last_law_name == 'è²¡æ”¿æ³•':
                    law_key = f'è²¡æ”¿æ³•ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                elif last_law_name == 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹':
                    law_key = f'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                else:
                    law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                
                by_law[law_key] = amount
                print(f"    [DEBUG] ã€ŒåŒæ³•ã€ã‚’å±•é–‹: {law_key} = {amount:,}å††")
        
        return by_law
    
    def _parse_item10(self, text: str) -> dict:
        """é …ç›®10: ç™ºè¡Œæ—¥"""
        match = re.search(r'ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥', text)
        if match:
            year = int(match.group(1)) + 2018
            month = int(match.group(2))
            day = int(match.group(3))
            return {'issue_date': f'{year}-{month:02d}-{day:02d}'}
        return {'raw': text}
    
    def _parse_item12(self, text: str) -> dict:
        """é …ç›®12: åˆ©ç‡"""
        match = re.search(r'å¹´([\d.]+)ï¼…', text)
        if match:
            return {'rate': float(match.group(1))}
        return {'raw': text}
    
    def _parse_item16(self, text: str) -> dict:
        """é …ç›®16: å„Ÿé‚„æœŸé™"""
        match = re.search(r'ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥', text)
        if match:
            year = int(match.group(1)) + 2018
            month = int(match.group(2))
            day = int(match.group(3))
            return {'maturity_date': f'{year}-{month:02d}-{day:02d}'}
        return {'raw': text}
    
    def _parse_item17(self, text: str) -> dict:
        """é …ç›®17: å„Ÿé‚„é‡‘é¡"""
        match = re.search(r'é¡é¢é‡‘é¡100å††ã«ã¤ã(\d+)å††', text)
        if match:
            return {'amount': int(match.group(1))}
        return {'raw': text}


def insert_to_bigquery(announcement_id: str, raw_text: str, items: dict, file_path: Path):
    """BigQueryã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥"""
    
    client = bigquery.Client(project=PROJECT_ID)
    
    # åŸºæœ¬æƒ…å ±ã®æŠ½å‡º
    issue_date = items.get(10, {}).get('structured_data', {}).get('issue_date', '2023-09-15')
    announcement_date = '2023-10-11'  # å‘Šç¤ºæ—¥ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ï¼‰
    announcement_number = 'ç¬¬äºŒç™¾äº”åä¸€å·'
    
    # Layer 1: raw_announcements ã«æŠ•å…¥
    raw_row = {
        'announcement_id': announcement_id,
        'announcement_date': announcement_date,
        'announcement_number': announcement_number,
        'issue_date': issue_date,
        'format_pattern': 'NUMBERED_LIST_MULTI_LAW',
        'format_pattern_confidence': 1.0,
        'raw_text': raw_text,
        'source_file': file_path.name,
        'file_path': str(file_path),
        'parsed': True,
        'parse_error': None,
        'parsed_at': datetime.now().isoformat()
    }
    
    table_ref = f"{PROJECT_ID}.{DATASET_ID}.raw_announcements"
    errors = client.insert_rows_json(table_ref, [raw_row])
    
    if errors:
        print(f"âŒ Layer 1 æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
        return False
    else:
        print(f"âœ… Layer 1 æŠ•å…¥æˆåŠŸ: {announcement_id}")
    
    # Layer 2: announcement_items ã«æŠ•å…¥
    item_rows = []
    for key, item_data in items.items():
        # ã‚­ãƒ¼ãŒæ–‡å­—åˆ—ï¼ˆ"6_1"ãªã©ï¼‰ã®å ´åˆã€item_numberã¨sub_numberã«åˆ†å‰²
        if isinstance(key, str) and '_' in key:
            parts = key.split('_')
            item_number = int(parts[0])
            sub_number = int(parts[1])
        else:
            item_number = int(key)
            sub_number = item_data.get('sub_number')
        
        item_row = {
            'item_id': f"{announcement_id}_item{key}",
            'announcement_id': announcement_id,
            'item_number': item_number,
            'sub_number': sub_number,
            'item_title': item_data['title'],
            'item_value': item_data['value'],
            'structured_data': json.dumps(item_data['structured_data'], ensure_ascii=False)
        }
        item_rows.append(item_row)
    
    table_ref = f"{PROJECT_ID}.{DATASET_ID}.announcement_items"
    errors = client.insert_rows_json(table_ref, item_rows)
    
    if errors:
        print(f"âŒ Layer 2 æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
        return False
    else:
        print(f"âœ… Layer 2 æŠ•å…¥æˆåŠŸ: {len(item_rows)} é …ç›®")
    
    return True


def prototype_test():
    """ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ†ã‚¹ãƒˆï¼šæ·»ä»˜ã®å‘Šç¤ºã‚’å‡¦ç†"""
    
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    file_path = Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20230915_ä»¤å’Œ5å¹´10æœˆ11æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬äºŒç™¾äº”åä¸€å·ï¼‰.txt")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        text = f.read()
    
    print("=" * 70)
    print("Phase 4 ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ†ã‚¹ãƒˆ: æ·»ä»˜ã®å‘Šç¤ºã‚’ãƒ‘ãƒ¼ã‚¹")
    print("=" * 70)
    print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«: {file_path.name}")
    print(f"ğŸ“ æ–‡å­—æ•°: {len(text):,}")
    print()
    
    # ãƒ‘ãƒ¼ã‚¹å®Ÿè¡Œ
    extractor = NumberedListExtractor()
    items = extractor.extract(text)
    
    print(f"âœ… ãƒ‘ãƒ¼ã‚¹å®Œäº†: {len(items)} é …ç›®æŠ½å‡º")
    print()
    
    # çµæœè¡¨ç¤ºï¼ˆä¸»è¦é …ç›®ã®ã¿ï¼‰
    print("-" * 70)
    print("ğŸ“Š æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼")
    print("-" * 70)
    
    if 1 in items:
        bond_info = items[1]['structured_data']
        print(f"éŠ˜æŸ„: {bond_info.get('bond_name', 'N/A')} {bond_info.get('bond_series', 'N/A')}")
    
    if 10 in items:
        print(f"ç™ºè¡Œæ—¥: {items[10]['structured_data'].get('issue_date', 'N/A')}")
    
    if 12 in items:
        print(f"åˆ©ç‡: {items[12]['structured_data'].get('rate', 'N/A')}%")
    
    if 16 in items:
        print(f"å„Ÿé‚„æœŸé™: {items[16]['structured_data'].get('maturity_date', 'N/A')}")
    
    print()
    
    # æ³•ä»¤åˆ¥ã®ç™ºè¡Œé¡ã‚’é›†è¨ˆ
    if 2 in items and 6 in items:
        print("-" * 70)
        print("ğŸ’° æ ¹æ‹ æ³•ä»¤åˆ¥ã®ç™ºè¡Œé¡é›†è¨ˆ")
        print("-" * 70)
        
        laws = items[2]['structured_data']['laws']
        issue_data = items[6]['structured_data']
        
        # å„æ³•ä»¤ã®ç™ºè¡Œé¡ã‚’è¨ˆç®—
        law_totals = {}
        
        for method in ['competitive', 'noncompetitive1', 'noncompetitive2']:
            if method in issue_data and 'by_law' in issue_data[method]:
                for law_key, amount in issue_data[method]['by_law'].items():
                    law_totals[law_key] = law_totals.get(law_key, 0) + amount
        
        print(f"\n{'æ³•ä»¤':<55} {'ç™ºè¡Œé¡ï¼ˆå††ï¼‰':>20} {'å…†å††':>10}")
        print("-" * 90)
        
        total = 0
        for law_key, amount in sorted(law_totals.items(), key=lambda x: x[1], reverse=True):
            trillion = amount / 1_000_000_000_000
            print(f"{law_key:<55} {amount:>20,} {trillion:>9.2f}")
            total += amount
        
        print("-" * 90)
        print(f"{'åˆè¨ˆ':<55} {total:>20,} {total/1_000_000_000_000:>9.2f}")
        print()
    
    # BigQueryã¸æŠ•å…¥
    print("-" * 70)
    print("ğŸ“¤ BigQuery ã¸ãƒ‡ãƒ¼ã‚¿æŠ•å…¥")
    print("-" * 70)
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’ä»˜ã‘ã¦é‡è¤‡ã‚’é¿ã‘ã‚‹
    announcement_id = "20230915_251_v3"
    success = insert_to_bigquery(announcement_id, text, items, file_path)
    
    if success:
        print()
        print("=" * 70)
        print("âœ… ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        print("=" * 70)
        print(f"Announcement ID: {announcement_id}")
        print(f"Layer 1: raw_announcements ã« 1è¡Œ æŠ•å…¥")
        print(f"Layer 2: announcement_items ã« {len(items)}è¡Œ æŠ•å…¥")
        print()
        print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: BigQueryã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        print(f"  SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.raw_announcements` LIMIT 10;")
        print(f"  SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.announcement_items` LIMIT 10;")
    else:
        print()
        print("âŒ ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    return items


if __name__ == "__main__":
    prototype_test()