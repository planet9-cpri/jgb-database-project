"""
Phase 5 çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼: Universal Announcement Parser (å®Œæˆç‰ˆ)
4ã¤ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’å®Œå…¨çµ±åˆã€BigQueryæŠ•å…¥ã€ãƒãƒƒãƒå‡¦ç†æ©Ÿèƒ½ã‚’å®Ÿè£…
"""

import re
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
import os
from google.cloud import bigquery

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\Users\sonke\secrets\jgb2023-f8c9b849ae2d.json'

PROJECT_ID = "jgb2023"
DATASET_ID = "20251028"


class NumberedListParser:
    """ç•ªå·ä»˜ããƒªã‚¹ãƒˆå½¢å¼ï¼ˆè¤‡æ•°æ³•ä»¤å¯¾å¿œ + ã‚·ãƒ³ãƒ—ãƒ«å˜ä¸€éŠ˜æŸ„å¯¾å¿œï¼‰"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰"""
        score = 0.0
        
        # å›½åº«çŸ­æœŸè¨¼åˆ¸ã®å ´åˆã¯ã‚¹ã‚³ã‚¢ã‚’å¤§å¹…ã«ä¸‹ã’ã‚‹
        if 'å›½åº«çŸ­æœŸè¨¼åˆ¸' in text or 'å‰²å¼•çŸ­æœŸå›½å‚µ' in text or 'æ”¿åºœçŸ­æœŸè¨¼åˆ¸' in text:
            return 0.1  # TBParserã«å„ªå…ˆã•ã›ã‚‹
        
        # åŸºæœ¬çš„ãªç•ªå·ä»˜ããƒªã‚¹ãƒˆæ§‹é€ ã®æ¤œå‡ºï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªå‘Šç¤ºç”¨ï¼‰
        # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã®æ•°ã«æŸ”è»Ÿã«å¯¾å¿œã™ã‚‹ãŸã‚ã€ã‚¹ãƒšãƒ¼ã‚¹éƒ¨åˆ†ã‚’æ­£è¦è¡¨ç¾ã§æ‰±ã†
        has_item1 = bool(re.search(r'ï¼‘\s+åç§°åŠã³è¨˜å·', text))
        has_item2 = bool(re.search(r'ï¼’.*?ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹', text, re.DOTALL))
        has_item_amount = bool(re.search(r'[ï¼•ï¼–]\s+.*?ç™º.*?è¡Œ.*?é¡', text))
        
        has_basic_structure = has_item1 and has_item2 and has_item_amount
        
        if has_basic_structure:
            score += 0.4  # åŸºæœ¬æ§‹é€ ãŒã‚ã‚Œã°0.4ç‚¹
        
        # ä¾¡æ ¼ç«¶äº‰å…¥æœ­ + éä¾¡æ ¼ç«¶äº‰å…¥æœ­ï¼ˆè¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        if 'ä¾¡æ ¼ç«¶äº‰å…¥æœ­' in text and 'éä¾¡æ ¼ç«¶äº‰å…¥æœ­' in text:
            score += 0.3
        
        # è¤‡æ•°æ³•ä»¤ï¼ˆä¸¦ã³ã«ã€åŠã³ï¼‰ï¼ˆè¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        if 'ä¸¦ã³ã«' in text and 'åŠã³' in text:
            score += 0.2
        
        # åˆ¥è¡¨ãŒãªã„ï¼ˆç•ªå·ä»˜ããƒªã‚¹ãƒˆã®ç‰¹å¾´ï¼‰
        if 'ï¼ˆåˆ¥è¡¨ã®ã¨ãŠã‚Šï¼‰' not in text and 'åˆ¥è¡¨' not in text:
            score += 0.3
        
        return min(score, 1.0)
    
    def extract(self, text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·
        match = re.search(r'ï¼‘\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\nï¼’)', text, re.DOTALL)
        if match:
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item1(match.group(1))
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …
        match = re.search(r'ï¼’\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\nï¼“)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item2(match.group(1))
            }
        
        # é …ç›®6: ç™ºè¡Œé¡ï¼ˆè¤‡é›‘ãªã®ã§è©³ç´°ã«ï¼‰
        match = re.search(r'ï¼–\s+ç™ºè¡Œé¡(.+?)(?=\nï¼—)', text, re.DOTALL)
        if match:
            full_text = match.group(1).strip()
            items[6] = {
                'title': 'ç™ºè¡Œé¡',
                'value': full_text,
                'sub_number': None,
                'structured_data': self._parse_item6(full_text)
            }
            
            # ã‚µãƒ–é …ç›®ã‚‚æŠ½å‡ºï¼ˆâ‘´â‘µâ‘¶ï¼‰
            sub_items = self._extract_sub_items(full_text)
            for sub_num, sub_data in sub_items.items():
                items[f'6_{sub_num}'] = {
                    'title': 'ç™ºè¡Œé¡â‘´â‘µâ‘¶',
                    'value': sub_data['value'],
                    'sub_number': sub_num,
                    'structured_data': sub_data['structured']
                }
        
        # é …ç›®10: ç™ºè¡Œæ—¥
        match = re.search(r'10\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\n11)', text, re.DOTALL)
        if match:
            items[10] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_date(match.group(1))
            }
        
        # é …ç›®12: åˆ©ç‡
        match = re.search(r'12\s+åˆ©ç‡\s+(.+?)(?=\n13)', text, re.DOTALL)
        if match:
            items[12] = {
                'title': 'åˆ©ç‡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item12(match.group(1))
            }
        
        # é …ç›®16: å„Ÿé‚„æœŸé™
        match = re.search(r'16\s+å„Ÿé‚„æœŸé™\s+(.+?)(?=\n17)', text, re.DOTALL)
        if match:
            items[16] = {
                'title': 'å„Ÿé‚„æœŸé™',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_date(match.group(1))
            }
        
        # é …ç›®17: å„Ÿé‚„é‡‘é¡
        match = re.search(r'17\s+å„Ÿé‚„é‡‘é¡\s+(.+?)(?=\n18)', text, re.DOTALL)
        if match:
            items[17] = {
                'title': 'å„Ÿé‚„é‡‘é¡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item17(match.group(1))
            }
        
        return {'pattern': 'NUMBERED_LIST_MULTI_LAW', 'items': items}
    
    def _extract_sub_items(self, text: str) -> dict:
        """â‘´â‘µâ‘¶ã®ã‚µãƒ–é …ç›®ã‚’æŠ½å‡º"""
        sub_items = {}
        
        # â‘´ã‚’æŠ½å‡º
        match1 = re.search(r'â‘´\s*ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)(?=â‘µ|$)', text, re.DOTALL)
        if match1:
            sub_items[1] = {
                'value': f'â‘´ ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match1.group(1).strip()}',
                'structured': self._parse_sub_item_amount(match1.group(1))
            }
        
        # â‘µã‚’æŠ½å‡º
        match2 = re.search(r'â‘µ\s*å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â… éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)(?=â‘¶|$)', text, re.DOTALL)
        if match2:
            sub_items[2] = {
                'value': f'â‘µ å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â… éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match2.group(1).strip()}',
                'structured': self._parse_sub_item_amount(match2.group(1))
            }
        
        # â‘¶ã‚’æŠ½å‡º
        match3 = re.search(r'â‘¶\s*å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â…¡éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)$', text, re.DOTALL)
        if match3:
            sub_items[3] = {
                'value': f'â‘¶ å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â…¡éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match3.group(1).strip()}',
                'structured': self._parse_sub_item_amount(match3.group(1))
            }
        
        return sub_items
    
    def _parse_sub_item_amount(self, text: str) -> dict:
        """ã‚µãƒ–é …ç›®ã‹ã‚‰ç™ºè¡Œé¡ã‚’æŠ½å‡ºï¼ˆã€ŒåŒæ³•ã€å¯¾å¿œç‰ˆï¼‰"""
        result = {'total_amount': 0, 'by_law': {}}
        
        # ç·é¡ã‚’æŠ½å‡º
        total_match = re.search(r'é¡é¢é‡‘é¡ã§([\d,]+)å††', text)
        if total_match:
            result['total_amount'] = int(total_match.group(1).replace(',', ''))
        
        # æ³•ä»¤åˆ¥ã®å†…è¨³
        last_law_name = None
        
        # æ˜ç¤ºçš„ãªæ³•ä»¤åã®ãƒãƒƒãƒ
        law_matches = re.finditer(
            r'([^ã€]+ç¬¬\d+æ¡ç¬¬\d+é …)ã®è¦å®šã«åŸºã¥ã.*?é¡é¢é‡‘é¡ã§([\d,]+)å††',
            text
        )
        
        for match in law_matches:
            law_ref = match.group(1).strip()
            amount = int(match.group(2).replace(',', ''))
            
            # æ³•å¾‹åã‚’æ­£è¦åŒ–
            law_key = self._normalize_law_name(law_ref)
            if law_key:
                result['by_law'][law_key] = amount
                
                # æ³•å¾‹åã‚’è¨˜æ†¶ï¼ˆã€ŒåŒæ³•ã€ç”¨ï¼‰
                if 'ç‰¹åˆ¥ä¼šè¨ˆ' in law_ref:
                    last_law_name = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿é‹å–¶' in law_ref:
                    last_law_name = 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿æ³•' in law_ref:
                    last_law_name = 'è²¡æ”¿æ³•'
        
        # ã€ŒåŒæ³•ç¬¬â—‹æ¡ç¬¬â—‹é …ã€ã®ãƒãƒƒãƒ
        same_law_matches = re.finditer(
            r'åŒæ³•ç¬¬(\d+)æ¡ç¬¬(\d+)é …ã®è¦å®šã«åŸºã¥ã.*?é¡é¢é‡‘é¡ã§([\d,]+)å††',
            text
        )
        
        for match in same_law_matches:
            article = match.group(1)
            paragraph = match.group(2)
            amount = int(match.group(3).replace(',', ''))
            
            if last_law_name:
                if last_law_name == 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹':
                    if article == '46':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'
                    elif article == '62':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …'
                    else:
                        law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                else:
                    law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                
                result['by_law'][law_key] = amount
        
        return result
    
    def _normalize_law_name(self, law_ref: str) -> str:
        """æ³•å¾‹åã‚’æ­£è¦åŒ–"""
        if 'è²¡æ”¿æ³•' in law_ref and 'ç¬¬ï¼”æ¡' in law_ref or 'ç¬¬4æ¡' in law_ref:
            return 'è²¡æ”¿æ³•ç¬¬4æ¡ç¬¬1é …'
        elif 'è²¡æ”¿é‹å–¶' in law_ref:
            return 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬3æ¡ç¬¬1é …'
        elif 'ç‰¹åˆ¥ä¼šè¨ˆ' in law_ref:
            if 'ç¬¬46æ¡' in law_ref:
                return 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'
            elif 'ç¬¬62æ¡' in law_ref:
                return 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …'
        return None
    
    def _parse_item1(self, text: str) -> dict:
        """é …ç›®1: åç§°åŠã³è¨˜å·ã‚’æ§‹é€ åŒ–"""
        match = re.search(r'åˆ©\s*ä»˜å›½åº«å‚µåˆ¸[ï¼ˆ\(](.+?)[ï¼‰\)][ï¼ˆ\(]ç¬¬(\d+)å›[ï¼‰\)]', text)
        if match:
            return {
                'bond_name': f'åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆ{match.group(1)}ï¼‰',
                'bond_series': f'ç¬¬{match.group(2)}å›'
            }
        return {'raw': text}
    
    def _parse_item2(self, text: str) -> dict:
        """é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹ã‚’æ§‹é€ åŒ–"""
        laws = []
        text_normalized = text.replace('ï¼”', '4').replace('ï¼“', '3').replace('ï¼‘', '1')
        
        # è²¡æ”¿æ³•ç¬¬4æ¡ç¬¬1é …
        if re.search(r'è²¡æ”¿æ³•.*?ç¬¬4æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'è²¡æ”¿æ³•',
                'full_name': 'è²¡æ”¿æ³•ï¼ˆæ˜­å’Œ22å¹´æ³•å¾‹ç¬¬34å·ï¼‰',
                'article': 'ç¬¬4æ¡ç¬¬1é …',
                'key': 'è²¡æ”¿æ³•ç¬¬4æ¡ç¬¬1é …',
                'amount': 0
            })
        
        # è²¡æ”¿é‹å–¶æ³•ç¬¬3æ¡ç¬¬1é …
        if re.search(r'è²¡æ”¿é‹å–¶.*?ç¬¬3æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ24å¹´æ³•å¾‹ç¬¬101å·ï¼‰',
                'article': 'ç¬¬3æ¡ç¬¬1é …',
                'key': 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬3æ¡ç¬¬1é …',
                'amount': 0
            })
        
        # ç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬46æ¡ç¬¬1é …
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        
        # ç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬62æ¡ç¬¬1é …
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬62æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬62æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …',
                'amount': 0
            })
        
        return {'laws': laws}
    
    def _parse_item6(self, text: str) -> dict:
        """é …ç›®6: ç™ºè¡Œé¡ã‚’æ§‹é€ åŒ–"""
        result = {
            'total_amount': 0,
            'competitive': {'amount': 0, 'by_law': {}},
            'noncompetitive1': {'amount': 0, 'by_law': {}},
            'noncompetitive2': {'amount': 0, 'by_law': {}}
        }
        
        # â‘´ ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ
        comp_match = re.search(r'â‘´\s*ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ\s*é¡é¢é‡‘é¡ã§([\d,]+)å††', text)
        if comp_match:
            amount = int(comp_match.group(1).replace(',', ''))
            result['competitive']['amount'] = amount
            result['total_amount'] += amount
            
            comp_section = re.search(r'â‘´(.+?)(?=â‘µ|$)', text, re.DOTALL)
            if comp_section:
                result['competitive']['by_law'] = self._extract_law_amounts_from_section(comp_section.group(1))
        
        # â‘µ ç¬¬â… éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ
        nc1_match = re.search(r'â‘µ.*?é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if nc1_match:
            amount = int(nc1_match.group(1).replace(',', ''))
            result['noncompetitive1']['amount'] = amount
            result['total_amount'] += amount
            
            nc1_section = re.search(r'â‘µ(.+?)(?=â‘¶|$)', text, re.DOTALL)
            if nc1_section:
                result['noncompetitive1']['by_law'] = self._extract_law_amounts_from_section(nc1_section.group(1))
        
        # â‘¶ ç¬¬â…¡éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ
        nc2_match = re.search(r'â‘¶.*?é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if nc2_match:
            amount = int(nc2_match.group(1).replace(',', ''))
            result['noncompetitive2']['amount'] = amount
            result['total_amount'] += amount
            
            nc2_section = re.search(r'â‘¶(.+?)$', text, re.DOTALL)
            if nc2_section:
                result['noncompetitive2']['by_law'] = self._extract_law_amounts_from_section(nc2_section.group(1))
        
        return result
    
    def _extract_law_amounts_from_section(self, section: str) -> dict:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æ³•ä»¤åˆ¥ã®ç™ºè¡Œé¡ã‚’æŠ½å‡ºï¼ˆã€ŒåŒæ³•ã€å¯¾å¿œç‰ˆï¼‰"""
        by_law = {}
        
        # æ˜ç¤ºçš„ãªæ³•ä»¤åã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒãƒƒãƒ
        law_matches = re.finditer(
            r'([^ã€]+ç¬¬\d+æ¡ç¬¬\d+é …)ã®è¦å®šã«åŸºã¥ã.*?é¡é¢é‡‘é¡ã§([\d,]+)å††',
            section
        )
        
        last_law_name = None
        
        for match in law_matches:
            law_ref = match.group(1).strip()
            amount = int(match.group(2).replace(',', ''))
            
            # æ³•å¾‹åã‚’æ­£è¦åŒ–
            law_key = self._normalize_law_name(law_ref)
            if law_key:
                by_law[law_key] = amount
                
                # æ³•å¾‹åã‚’è¨˜æ†¶ï¼ˆã€ŒåŒæ³•ã€ç”¨ï¼‰
                if 'ç‰¹åˆ¥ä¼šè¨ˆ' in law_ref:
                    last_law_name = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿é‹å–¶' in law_ref:
                    last_law_name = 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿æ³•' in law_ref:
                    last_law_name = 'è²¡æ”¿æ³•'
        
        # ã€ŒåŒæ³•ç¬¬â—‹æ¡ç¬¬â—‹é …ã€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒãƒƒãƒ
        same_law_matches = re.finditer(
            r'åŒæ³•ç¬¬(\d+)æ¡ç¬¬(\d+)é …ã®è¦å®šã«åŸºã¥ã.*?é¡é¢é‡‘é¡ã§([\d,]+)å††',
            section
        )
        
        for match in same_law_matches:
            article = match.group(1)
            paragraph = match.group(2)
            amount = int(match.group(3).replace(',', ''))
            
            if last_law_name:
                if last_law_name == 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹':
                    if article == '46':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'
                    elif article == '62':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …'
                    else:
                        law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                else:
                    law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                
                by_law[law_key] = amount
        
        return by_law
    
    def _parse_date(self, text: str) -> dict:
        """æ—¥ä»˜ã‚’è§£æ"""
        match = re.search(r'ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥', text)
        if match:
            year = int(match.group(1)) + 2018
            month = int(match.group(2))
            day = int(match.group(3))
            return {'issue_date': f'{year}-{month:02d}-{day:02d}'}
        return {'raw': text}
    
    def _parse_item12(self, text: str) -> dict:
        """é …ç›®12: åˆ©ç‡"""
        match = re.search(r'å¹´([\d.]+)ï¼…', text)
        if match:
            return {'rate': float(match.group(1))}
        return {'raw': text}
    
    def _parse_item17(self, text: str) -> dict:
        """é …ç›®17: å„Ÿé‚„é‡‘é¡"""
        match = re.search(r'é¡é¢é‡‘é¡100å††ã«ã¤ã(\d+)å††', text)
        if match:
            return {'amount': int(match.group(1))}
        return {'raw': text}


class TableParserV4:
    """æ¨ªä¸¦ã³åˆ¥è¡¨å½¢å¼ã®å‘Šç¤ºã‚’è§£æ"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰"""
        score = 0.0
        
        # åˆ¥è¡¨ã®å­˜åœ¨
        if 'ï¼ˆåˆ¥è¡¨ã®ã¨ãŠã‚Šï¼‰' in text or 'å†…è¨³ï¼ˆåˆ¥è¡¨ã®ã¨ãŠã‚Šï¼‰' in text:
            score += 0.4
        
        # åˆ¥è¡¨ã®å®Ÿãƒ‡ãƒ¼ã‚¿
        if 'åç§°åŠã³è¨˜å·' in text and 'åˆ©ç‡' in text and 'å„Ÿé‚„æœŸé™' in text:
            score += 0.4
        
        # åˆ¥è¡¨ãƒ˜ãƒƒãƒ€ãƒ¼ã®å­˜åœ¨
        if 'ï¼ˆåˆ¥è¡¨ï¼‰' in text:
            score += 0.2
        
        return min(score, 1.0)
    
    def extract(self, text: str) -> Dict[str, Any]:
        """å‘Šç¤ºã‹ã‚‰ç•ªå·ä»˜ããƒªã‚¹ãƒˆã¨åˆ¥è¡¨ã‚’æŠ½å‡º"""
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·ï¼ˆè¤‡æ•°éŠ˜æŸ„ï¼‰
        match = re.search(r'ï¼‘\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\nï¼’)', text, re.DOTALL)
        if match:
            bond_names = self._parse_multiple_bond_names(match.group(1))
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'bond_names': bond_names}
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹
        match = re.search(r'ï¼’\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\nï¼“)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_laws(match.group(1))
            }
        
        # é …ç›®6: ç™ºè¡Œé¡ï¼ˆåˆ¥è¡¨å‚ç…§ï¼‰
        match = re.search(r'ï¼–\s+ç™ºè¡Œé¡\s+é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if match:
            total_amount = int(match.group(1).replace(',', ''))
            items[6] = {
                'title': 'ç™ºè¡Œé¡',
                'value': f'é¡é¢é‡‘é¡ã§{match.group(1)}å††\nå†…è¨³ï¼ˆåˆ¥è¡¨ã®ã¨ãŠã‚Šï¼‰',
                'sub_number': None,
                'structured_data': {'total_amount': total_amount}
            }
        
        # é …ç›®10: ç™ºè¡Œæ—¥
        match = re.search(r'10\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\n11)', text, re.DOTALL)
        if match:
            items[10] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_date(match.group(1))
            }
        
        # åˆ¥è¡¨ã®è§£æ
        table_data = self._parse_table(text)
        if table_data:
            # åˆ¥è¡¨ã®å„è¡Œã‚’é …ç›®6ã®ã‚µãƒ–é …ç›®ã¨ã—ã¦è¿½åŠ 
            for i, row in enumerate(table_data, start=1):
                items[f'6_{i}'] = {
                    'title': 'ç™ºè¡Œé¡ï¼ˆåˆ¥è¡¨ï¼‰',
                    'value': self._format_table_row(row),
                    'sub_number': i,
                    'structured_data': row
                }
        
        return {'pattern': 'TABLE_HORIZONTAL', 'items': items}
    
    def _parse_multiple_bond_names(self, text: str) -> list:
        """è¤‡æ•°ã®éŠ˜æŸ„åã‚’æŠ½å‡º"""
        bond_names = []
        parts = re.split(r'åŠã³', text)
        
        for part in parts:
            part = part.strip()
            if 'åˆ©ä»˜å›½åº«å‚µåˆ¸' in part:
                bond_names.append(part)
        
        return bond_names
    
    def _parse_laws(self, text: str) -> dict:
        """æ³•ä»¤ã‚’æŠ½å‡º"""
        laws = []
        text_normalized = text.replace('ï¼”', '4').replace('ï¼–', '6').replace('ï¼’', '2').replace('ï¼‘', '1')
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬62æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬62æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …',
                'amount': 0
            })
        
        return {'laws': laws}
    
    def _parse_date(self, text: str) -> dict:
        """ç™ºè¡Œæ—¥ã‚’è§£æ"""
        match = re.search(r'ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥', text)
        if match:
            year = int(match.group(1)) + 2018
            month = int(match.group(2))
            day = int(match.group(3))
            return {'issue_date': f'{year}-{month:02d}-{day:02d}'}
        return {'raw': text}
    
    def _parse_table(self, text: str) -> list:
        """åˆ¥è¡¨ã‚’è§£æ"""
        table_start = text.find('ï¼ˆåˆ¥è¡¨ï¼‰')
        if table_start == -1:
            return []
        
        table_text = text[table_start:]
        rows = []
        
        # åˆ¥è¡¨ã®è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³
        pattern = r'åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆ(.+?)ï¼‰ï¼ˆç¬¬(\d+)å›ï¼‰\s+([\d.]+)ï¼…\s+ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥\s+ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬(\d+)æ¡ç¬¬ï¼‘é …åˆ†\s+([\d,]+)å††'
        
        matches = re.finditer(pattern, table_text)
        
        for match in matches:
            bond_type = match.group(1)
            series = match.group(2)
            rate = float(match.group(3))
            maturity_year = int(match.group(4)) + 2018
            maturity_month = int(match.group(5))
            maturity_day = int(match.group(6))
            law_article = match.group(7)
            amount = int(match.group(8).replace(',', ''))
            
            law_key = f'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬{law_article}æ¡ç¬¬1é …'
            
            row = {
                'bond_name': f'åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆ{bond_type}ï¼‰',
                'bond_series': f'ç¬¬{series}å›',
                'interest_rate': rate,
                'maturity_date': f'{maturity_year}-{maturity_month:02d}-{maturity_day:02d}',
                'law_key': law_key,
                'law_article': f'ç¬¬{law_article}æ¡ç¬¬1é …',
                'issue_amount': amount
            }
            
            rows.append(row)
        
        return rows
    
    def _format_table_row(self, row: dict) -> str:
        """è¡¨ã®è¡Œã‚’æ–‡å­—åˆ—ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return (f"{row['bond_name']}{row['bond_series']}: "
                f"åˆ©ç‡{row['interest_rate']}%, "
                f"å„Ÿé‚„æœŸé™{row['maturity_date']}, "
                f"{row['law_key']}, "
                f"ç™ºè¡Œé¡{row['issue_amount']:,}å††")


class RetailBondParser:
    """å€‹äººå‘ã‘å›½å‚µã®å‘Šç¤ºã‚’è§£æ"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰"""
        if 'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸' in text or 'å€‹äººå‘ã‘å›½å‚µ' in text:
            return 1.0
        return 0.0
    
    def extract(self, text: str) -> Dict[str, Any]:
        """å‘Šç¤ºã‹ã‚‰ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚’æŠ½å‡º"""
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·
        match = re.search(r'ï¼‘\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\nï¼’)', text, re.DOTALL)
        if match:
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item1(match.group(1))
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹
        match = re.search(r'ï¼’\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\nï¼“)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_laws(match.group(1))
            }
        
        # é …ç›®4: ç™ºè¡Œé¡ï¼ˆå€‹äººå‘ã‘ã¯é …ç›®4ï¼‰
        match = re.search(r'ï¼”\s+ç™ºè¡Œé¡\s+é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if match:
            total_amount = int(match.group(1).replace(',', ''))
            items[4] = {
                'title': 'ç™ºè¡Œé¡',
                'value': f'é¡é¢é‡‘é¡ã§{match.group(1)}å††',
                'sub_number': None,
                'structured_data': {'total_amount': total_amount}
            }
        
        # é …ç›®7: ç™ºè¡Œæ—¥ï¼ˆå€‹äººå‘ã‘ã¯é …ç›®7ï¼‰
        match = re.search(r'ï¼—\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\nï¼˜)', text, re.DOTALL)
        if match:
            items[7] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_date(match.group(1))
            }
        
        # é …ç›®9: åˆæœŸåˆ©å­ã®é©ç”¨åˆ©ç‡
        match = re.search(r'ï¼™\s+åˆæœŸåˆ©å­ã®é©ç”¨åˆ©ç‡\s+å¹´([\d.]+)ï¼…', text, re.DOTALL)
        if match:
            items[9] = {
                'title': 'åˆæœŸåˆ©å­ã®é©ç”¨åˆ©ç‡',
                'value': f'å¹´{match.group(1)}ï¼…',
                'sub_number': None,
                'structured_data': {'rate': float(match.group(1))}
            }
        
        # é …ç›®13: å„Ÿé‚„æœŸé™
        match = re.search(r'13\s+å„Ÿé‚„æœŸé™\s+(.+?)(?=\n14)', text, re.DOTALL)
        if match:
            items[13] = {
                'title': 'å„Ÿé‚„æœŸé™',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_date(match.group(1))
            }
        
        # é …ç›®14: å„Ÿé‚„é‡‘é¡
        match = re.search(r'14\s+å„Ÿé‚„é‡‘é¡\s+(.+?)(?=\n15)', text, re.DOTALL)
        if match:
            items[14] = {
                'title': 'å„Ÿé‚„é‡‘é¡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_redemption_amount(match.group(1))
            }
        
        return {'pattern': 'RETAIL_BOND', 'items': items}
    
    def _parse_item1(self, text: str) -> dict:
        """é …ç›®1: åç§°åŠã³è¨˜å·ã‚’æ§‹é€ åŒ–"""
        match = re.search(r'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸[ï¼ˆ\(](.+?)[ï¼‰\)][ï¼ˆ\(]ç¬¬(\d+)å›[ï¼‰\)]', text)
        if match:
            return {
                'bond_name': f'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸ï¼ˆ{match.group(1)}ï¼‰',
                'bond_series': f'ç¬¬{match.group(2)}å›',
                'bond_type': match.group(1)
            }
        return {'raw': text}
    
    def _parse_laws(self, text: str) -> dict:
        """æ³•ä»¤ã‚’æŠ½å‡º"""
        laws = []
        text_normalized = text.replace('ï¼”', '4').replace('ï¼–', '6').replace('ï¼‘', '1')
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        
        return {'laws': laws}
    
    def _parse_date(self, text: str) -> dict:
        """ç™ºè¡Œæ—¥ã‚’è§£æ"""
        match = re.search(r'ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥', text)
        if match:
            year = int(match.group(1)) + 2018
            month = int(match.group(2))
            day = int(match.group(3))
            return {'issue_date': f'{year}-{month:02d}-{day:02d}'}
        return {'raw': text}
    
    def _parse_redemption_amount(self, text: str) -> dict:
        """å„Ÿé‚„é‡‘é¡ã‚’è§£æ"""
        match = re.search(r'é¡é¢é‡‘é¡100å††ã«ã¤ã(\d+)å††', text)
        if match:
            return {'amount': int(match.group(1))}
        return {'raw': text}


class TBParser:
    """å›½åº«çŸ­æœŸè¨¼åˆ¸ï¼ˆTreasury Billï¼‰ã®å‘Šç¤ºã‚’è§£æ"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0ï½1.0ï¼‰"""
        score = 0.0
        
        if 'å›½åº«çŸ­æœŸè¨¼åˆ¸' in text:
            score += 0.5
        
        if 'å‰²å¼•çŸ­æœŸå›½å‚µ' in text or 'æ”¿åºœçŸ­æœŸè¨¼åˆ¸' in text:
            score += 0.5
        
        return min(score, 1.0)
    
    def extract(self, text: str) -> Dict[str, Any]:
        """å‘Šç¤ºã‹ã‚‰ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚’æŠ½å‡º"""
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·
        match = re.search(r'ï¼‘\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\nï¼’)', text, re.DOTALL)
        if match:
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item1(match.group(1))
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹ï¼ˆè¤‡é›‘ï¼‰
        match = re.search(r'ï¼’\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\nï¼“)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_laws(match.group(1))
            }
        
        # é …ç›®6: ç™ºè¡Œé¡ï¼ˆè¤‡é›‘ï¼š2ç¨®é¡ã®è¨¼åˆ¸ï¼‰
        match = re.search(r'ï¼–\s+ç™ºè¡Œé¡(.+?)(?=\nï¼—)', text, re.DOTALL)
        if match:
            full_text = match.group(1).strip()
            items[6] = {
                'title': 'ç™ºè¡Œé¡',
                'value': full_text,
                'sub_number': None,
                'structured_data': self._parse_item6(full_text)
            }
            
            # ã‚µãƒ–é …ç›®ã‚‚æŠ½å‡ºï¼ˆâ‘´â‘µï¼‰
            sub_items = self._extract_sub_items(full_text)
            for sub_num, sub_data in sub_items.items():
                items[f'6_{sub_num}'] = {
                    'title': 'ç™ºè¡Œé¡â‘´â‘µ',
                    'value': sub_data['value'],
                    'sub_number': sub_num,
                    'structured_data': sub_data['structured']
                }
        
        # é …ç›®10: ç™ºè¡Œæ—¥
        match = re.search(r'10\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\n11)', text, re.DOTALL)
        if match:
            items[10] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_date(match.group(1))
            }
        
        # é …ç›®12: å„Ÿé‚„æœŸé™
        match = re.search(r'12\s+å„Ÿé‚„æœŸé™\s+(.+?)(?=\n13)', text, re.DOTALL)
        if match:
            items[12] = {
                'title': 'å„Ÿé‚„æœŸé™',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_date(match.group(1))
            }
        
        # é …ç›®13: å„Ÿé‚„é‡‘é¡
        match = re.search(r'13\s+å„Ÿé‚„é‡‘é¡\s+(.+?)(?=\n14)', text, re.DOTALL)
        if match:
            items[13] = {
                'title': 'å„Ÿé‚„é‡‘é¡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_redemption_amount(match.group(1))
            }
        
        return {'pattern': 'TB_SHORT_TERM', 'items': items}
    
    def _parse_item1(self, text: str) -> dict:
        """é …ç›®1: åç§°åŠã³è¨˜å·ã‚’æ§‹é€ åŒ–"""
        match = re.search(r'å›½åº«çŸ­æœŸè¨¼åˆ¸[ï¼ˆ\(]ç¬¬(\d+)å›[ï¼‰\)]', text)
        if match:
            return {
                'bond_name': 'å›½åº«çŸ­æœŸè¨¼åˆ¸',
                'bond_series': f'ç¬¬{match.group(1)}å›'
            }
        return {'raw': text}
    
    def _parse_laws(self, text: str) -> dict:
        """æ³•ä»¤ã‚’æŠ½å‡ºï¼ˆè¤‡é›‘ï¼šè¤‡æ•°æ³•ä»¤ï¼‰"""
        laws = []
        text_normalized = text.replace('ï¼”', '4').replace('ï¼–', '6').replace('ï¼—', '7').replace('ï¼™', '9').replace('ï¼“', '3').replace('ï¼˜', '8').replace('ï¼‘', '1').replace('ï¼’', '2').replace('ï¼•', '5')
        
        # ç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬46æ¡ç¬¬1é …
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text_normalized, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆå¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·ï¼‰',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        
        # æ”¿åºœçŸ­æœŸè¨¼åˆ¸ç”¨ã®æ³•ä»¤ã‚°ãƒ«ãƒ¼ãƒ—
        tb_articles = ['83', '94', '95', '136', '137']
        if any(f'ç¬¬{a}æ¡' in text_normalized for a in tb_articles):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆæ”¿åºœçŸ­æœŸè¨¼åˆ¸ï¼‰',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ï¼ˆè¤‡æ•°æ¡é …ï¼‰',
                'article': 'ç¬¬83æ¡ç­‰',
                'key': 'æ”¿åºœçŸ­æœŸè¨¼åˆ¸é–¢é€£æ³•ä»¤',
                'amount': 0
            })
        
        return {'laws': laws}
    
    def _extract_sub_items(self, text: str) -> dict:
        """â‘´â‘µã®ã‚µãƒ–é …ç›®ã‚’æŠ½å‡º"""
        sub_items = {}
        
        # â‘´ ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ
        match1 = re.search(r'â‘´\s*ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ\s*é¡é¢é‡‘é¡ã§([\d,]+)å††(.+?)(?=â‘µ|$)', text, re.DOTALL)
        if match1:
            total_amount = int(match1.group(1).replace(',', ''))
            detail = match1.group(2)
            
            sub_items[1] = {
                'value': f'â‘´ ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ é¡é¢é‡‘é¡ã§{match1.group(1)}å††',
                'structured': self._parse_sub_item_amount(detail, total_amount)
            }
        
        # â‘µ ç¬¬â… éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ
        match2 = re.search(r'â‘µ\s*å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â… éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)$', text, re.DOTALL)
        if match2:
            detail = match2.group(1)
            amount_match = re.search(r'é¡é¢é‡‘é¡ã§([\d,]+)å††', detail)
            if amount_match:
                total_amount = int(amount_match.group(1).replace(',', ''))
                sub_items[2] = {
                    'value': f'â‘µ å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€…ãƒ»ç¬¬â… éä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ',
                    'structured': self._parse_sub_item_amount(detail, total_amount)
                }
        
        return sub_items
    
    def _parse_sub_item_amount(self, text: str, total_amount: int) -> dict:
        """ã‚µãƒ–é …ç›®ã‹ã‚‰ç™ºè¡Œé¡ã‚’æŠ½å‡º"""
        result = {'total_amount': total_amount, 'by_law': {}}
        
        # å‰²å¼•çŸ­æœŸå›½å‚µï¼ˆç‰¹åˆ¥ä¼šè¨ˆæ³•ç¬¬46æ¡ç¬¬1é …ï¼‰
        tb_match = re.search(r'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬ï¼‘é …ã®è¦å®šã«åŸºã¥ãç™ºè¡Œã—ãŸå‰²å¼•çŸ­æœŸå›½å‚µ.*?é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if tb_match:
            amount = int(tb_match.group(1).replace(',', ''))
            result['by_law']['ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'] = amount
        
        # æ”¿åºœçŸ­æœŸè¨¼åˆ¸ï¼ˆè¤‡æ•°æ³•ä»¤ï¼‰
        gsb_match = re.search(r'è²¡æ”¿æ³•ç¬¬ï¼—æ¡ç¬¬ï¼‘é ….*?æ”¿åºœçŸ­æœŸè¨¼åˆ¸.*?é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if gsb_match:
            amount = int(gsb_match.group(1).replace(',', ''))
            result['by_law']['æ”¿åºœçŸ­æœŸè¨¼åˆ¸é–¢é€£æ³•ä»¤'] = amount
        
        return result
    
    def _parse_item6(self, text: str) -> dict:
        """é …ç›®6: ç™ºè¡Œé¡ã‚’æ§‹é€ åŒ–"""
        result = {
            'total_amount': 0,
            'competitive': {'amount': 0, 'by_law': {}},
            'noncompetitive1': {'amount': 0, 'by_law': {}}
        }
        
        # â‘´ ä¾¡æ ¼ç«¶äº‰å…¥æœ­
        comp_match = re.search(r'â‘´\s*ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ\s*é¡é¢é‡‘é¡ã§([\d,]+)å††', text)
        if comp_match:
            amount = int(comp_match.group(1).replace(',', ''))
            result['competitive']['amount'] = amount
            result['total_amount'] += amount
            
            comp_section = re.search(r'â‘´(.+?)(?=â‘µ|$)', text, re.DOTALL)
            if comp_section:
                result['competitive']['by_law'] = self._extract_law_amounts_from_section(comp_section.group(1))
        
        # â‘µ ç¬¬â… éä¾¡æ ¼ç«¶äº‰
        nc1_match = re.search(r'â‘µ.*?é¡é¢é‡‘é¡ã§([\d,]+)å††', text, re.DOTALL)
        if nc1_match:
            amount = int(nc1_match.group(1).replace(',', ''))
            result['noncompetitive1']['amount'] = amount
            result['total_amount'] += amount
            
            nc1_section = re.search(r'â‘µ(.+?)$', text, re.DOTALL)
            if nc1_section:
                result['noncompetitive1']['by_law'] = self._extract_law_amounts_from_section(nc1_section.group(1))
        
        return result
    
    def _extract_law_amounts_from_section(self, section: str) -> dict:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æ³•ä»¤åˆ¥ã®ç™ºè¡Œé¡ã‚’æŠ½å‡º"""
        by_law = {}
        
        # å‰²å¼•çŸ­æœŸå›½å‚µ
        tb_match = re.search(r'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬ï¼‘é …ã®è¦å®šã«åŸºã¥ãç™ºè¡Œã—ãŸå‰²å¼•çŸ­æœŸå›½å‚µ.*?é¡é¢é‡‘é¡ã§([\d,]+)å††', section, re.DOTALL)
        if tb_match:
            amount = int(tb_match.group(1).replace(',', ''))
            by_law['ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'] = amount
        
        # æ”¿åºœçŸ­æœŸè¨¼åˆ¸
        gsb_match = re.search(r'è²¡æ”¿æ³•ç¬¬ï¼—æ¡ç¬¬ï¼‘é ….*?æ”¿åºœçŸ­æœŸè¨¼åˆ¸.*?é¡é¢é‡‘é¡ã§([\d,]+)å††', section, re.DOTALL)
        if gsb_match:
            amount = int(gsb_match.group(1).replace(',', ''))
            by_law['æ”¿åºœçŸ­æœŸè¨¼åˆ¸é–¢é€£æ³•ä»¤'] = amount
        
        return by_law
    
    def _parse_date(self, text: str) -> dict:
        """ç™ºè¡Œæ—¥ã‚’è§£æ"""
        match = re.search(r'ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥', text)
        if match:
            year = int(match.group(1)) + 2018
            month = int(match.group(2))
            day = int(match.group(3))
            return {'issue_date': f'{year}-{month:02d}-{day:02d}'}
        return {'raw': text}
    
    def _parse_redemption_amount(self, text: str) -> dict:
        """å„Ÿé‚„é‡‘é¡ã‚’è§£æ"""
        match = re.search(r'é¡é¢é‡‘é¡100å††ã«ã¤ã(\d+)å††', text)
        if match:
            return {'amount': int(match.group(1))}
        return {'raw': text}


class UniversalAnnouncementParser:
    """çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ï¼šã™ã¹ã¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼ˆå®Œæˆç‰ˆï¼‰"""
    
    def __init__(self):
        # 4ã¤ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ç™»éŒ²ï¼ˆå„ªå…ˆé †ä½é †ï¼‰
        self.parsers = [
            ('RETAIL_BOND', RetailBondParser()),
            ('TABLE_HORIZONTAL', TableParserV4()),
            ('TB_SHORT_TERM', TBParser()),
            ('NUMBERED_LIST_MULTI_LAW', NumberedListParser()),
        ]
        
        self.client = bigquery.Client(project=PROJECT_ID)
    
    def identify_pattern(self, text: str) -> Tuple[str, float]:
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•è­˜åˆ¥
        
        Returns:
            (pattern_name, confidence_score)
        """
        scores = {}
        
        for pattern_name, parser in self.parsers:
            score = parser.can_parse(text)
            scores[pattern_name] = score
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
        best_pattern = max(scores.items(), key=lambda x: x[1])
        
        return best_pattern[0], best_pattern[1]
    
    def parse(self, text: str, file_path: Optional[Path] = None) -> Dict[str, Any]:
        """
        å‘Šç¤ºã‚’è§£æ
        
        Returns:
            {
                'pattern': ãƒ‘ã‚¿ãƒ¼ãƒ³å,
                'confidence': ä¿¡é ¼åº¦,
                'items': æŠ½å‡ºãƒ‡ãƒ¼ã‚¿,
                'error': ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚ã‚Œã°ï¼‰,
                'file_path': ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            }
        """
        try:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥
            pattern, confidence = self.identify_pattern(text)
            
            # ä¿¡é ¼åº¦ãŒä½ã™ãã‚‹å ´åˆã¯è­¦å‘Š
            if confidence < 0.5:
                return {
                    'pattern': 'UNKNOWN',
                    'confidence': confidence,
                    'items': {},
                    'error': f'ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥ã®ä¿¡é ¼åº¦ãŒä½ã„ï¼ˆ{confidence:.2f}ï¼‰',
                    'file_path': str(file_path) if file_path else None
                }
            
            # é©åˆ‡ãªãƒ‘ãƒ¼ã‚µãƒ¼ã‚’é¸æŠ
            parser = None
            for p_name, p in self.parsers:
                if p_name == pattern:
                    parser = p
                    break
            
            if parser is None:
                return {
                    'pattern': pattern,
                    'confidence': confidence,
                    'items': {},
                    'error': f'ãƒ‘ãƒ¼ã‚µãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}',
                    'file_path': str(file_path) if file_path else None
                }
            
            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            result = parser.extract(text)
            
            return {
                'pattern': result['pattern'],
                'confidence': confidence,
                'items': result.get('items', {}),
                'error': None,
                'file_path': str(file_path) if file_path else None
            }
        
        except Exception as e:
            return {
                'pattern': 'ERROR',
                'confidence': 0.0,
                'items': {},
                'error': str(e),
                'file_path': str(file_path) if file_path else None
            }
    
    def extract_metadata_from_filename(self, file_path: Path) -> Dict[str, str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        filename = file_path.stem
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ‘ã‚¿ãƒ¼ãƒ³: 20230915_ä»¤å’Œ5å¹´10æœˆ11æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬äºŒç™¾äº”åä¸€å·ï¼‰
        match = re.match(r'(\d{8})_ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥ä»˜ï¼ˆè²¡å‹™çœ(.+?)ï¼‰', filename)
        
        if match:
            file_date = match.group(1)
            reiwa_year = int(match.group(2))
            month = int(match.group(3))
            day = int(match.group(4))
            announcement_num = match.group(5)
            
            announcement_year = reiwa_year + 2018
            announcement_date = f'{announcement_year}-{month:02d}-{day:02d}'
            
            return {
                'file_date': file_date,
                'announcement_date': announcement_date,
                'announcement_number': announcement_num
            }
        
        return {
            'file_date': 'unknown',
            'announcement_date': 'unknown',
            'announcement_number': 'unknown'
        }
    
    def insert_to_bigquery(
        self,
        announcement_id: str,
        raw_text: str,
        items: dict,
        file_path: Path,
        pattern: str,
        confidence: float
    ) -> bool:
        """BigQueryã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥"""
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            metadata = self.extract_metadata_from_filename(file_path)
            
            # ç™ºè¡Œæ—¥ã‚’æŠ½å‡ºï¼ˆé …ç›®10ã¾ãŸã¯é …ç›®7ï¼‰
            issue_date = None
            if 10 in items:
                issue_date = items[10].get('structured_data', {}).get('issue_date')
            elif 7 in items:
                issue_date = items[7].get('structured_data', {}).get('issue_date')
            
            if not issue_date:
                issue_date = metadata['announcement_date']
            
            # Layer 1: raw_announcements ã«æŠ•å…¥
            raw_row = {
                'announcement_id': announcement_id,
                'announcement_date': metadata['announcement_date'],
                'announcement_number': metadata['announcement_number'],
                'issue_date': issue_date,
                'format_pattern': pattern,
                'format_pattern_confidence': confidence,
                'raw_text': raw_text,
                'source_file': file_path.name,
                'file_path': str(file_path),
                'parsed': True,
                'parse_error': None,
                'parsed_at': datetime.now().isoformat()
            }
            
            table_ref = f"{PROJECT_ID}.{DATASET_ID}.raw_announcements"
            errors = self.client.insert_rows_json(table_ref, [raw_row])
            
            if errors:
                print(f"  âŒ Layer 1 æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
                return False
            
            # Layer 2: announcement_items ã«æŠ•å…¥
            item_rows = []
            for key, item_data in items.items():
                # ã‚­ãƒ¼ãŒæ–‡å­—åˆ—ï¼ˆ"6_1"ãªã©ï¼‰ã®å ´åˆã€item_numberã¨sub_numberã«åˆ†å‰²
                if isinstance(key, str) and '_' in key:
                    parts = key.split('_')
                    item_number = int(parts[0])
                    sub_number = int(parts[1])
                else:
                    item_number = int(key)
                    sub_number = item_data.get('sub_number')
                
                item_row = {
                    'item_id': f"{announcement_id}_item{key}",
                    'announcement_id': announcement_id,
                    'item_number': item_number,
                    'sub_number': sub_number,
                    'item_title': item_data['title'],
                    'item_value': item_data['value'],
                    'structured_data': json.dumps(item_data['structured_data'], ensure_ascii=False)
                }
                item_rows.append(item_row)
            
            table_ref = f"{PROJECT_ID}.{DATASET_ID}.announcement_items"
            errors = self.client.insert_rows_json(table_ref, item_rows)
            
            if errors:
                print(f"  âŒ Layer 2 æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
                return False
            
            return True
        
        except Exception as e:
            print(f"  âŒ BigQueryæŠ•å…¥ä¾‹å¤–: {e}")
            return False


def batch_process(
    input_dir: Path,
    dataset_id: str = DATASET_ID,
    test_mode: bool = True,
    max_files: int = 10,
    insert_to_bq: bool = True
) -> Dict[str, Any]:
    """
    ãƒãƒƒãƒå‡¦ç†ï¼šè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†
    
    Args:
        input_dir: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        dataset_id: BigQueryãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆID
        test_mode: ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆTrueã§æœ€å¤§max_filesä»¶ï¼‰
        max_files: ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰æ™‚ã®æœ€å¤§å‡¦ç†ä»¶æ•°
        insert_to_bq: BigQueryã«æŠ•å…¥ã™ã‚‹ã‹
    
    Returns:
        å‡¦ç†çµæœã®çµ±è¨ˆæƒ…å ±
    """
    parser = UniversalAnnouncementParser()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
    files = sorted(input_dir.glob('*.txt'))
    
    if test_mode:
        files = files[:max_files]
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®{len(files)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
    else:
        print(f"ğŸš€ æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰: {len(files)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
    
    print(f"ğŸ“¤ BigQueryæŠ•å…¥: {'æœ‰åŠ¹' if insert_to_bq else 'ç„¡åŠ¹'}")
    print()
    
    # çµ±è¨ˆæƒ…å ±
    stats = {
        'total': len(files),
        'success': 0,
        'failed': 0,
        'by_pattern': {},
        'errors': [],
        'inserted': 0
    }
    
    for i, file_path in enumerate(files, 1):
        print(f"[{i}/{len(files)}] {file_path.name}")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            # ãƒ‘ãƒ¼ã‚¹
            result = parser.parse(text, file_path)
            
            pattern = result['pattern']
            confidence = result['confidence']
            
            print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern} (ä¿¡é ¼åº¦: {confidence:.2f})")
            
            # çµ±è¨ˆæ›´æ–°
            if pattern not in stats['by_pattern']:
                stats['by_pattern'][pattern] = 0
            stats['by_pattern'][pattern] += 1
            
            if result['error']:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
                stats['failed'] += 1
                stats['errors'].append({
                    'file': file_path.name,
                    'pattern': pattern,
                    'error': result['error']
                })
            else:
                print(f"  âœ… ãƒ‘ãƒ¼ã‚¹æˆåŠŸ")
                stats['success'] += 1
                
                # BigQueryæŠ•å…¥
                if insert_to_bq:
                    # announcement_idã‚’ç”Ÿæˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ï¼‰
                    match = re.match(r'(\d{8})_.*ï¼ˆè²¡å‹™çœ(.+?)ï¼‰', file_path.name)
                    if match:
                        date_part = match.group(1)
                        num_part = match.group(2).replace('ç¬¬', '').replace('å·', '')
                        announcement_id = f"{date_part}_{num_part}"
                    else:
                        announcement_id = file_path.stem
                    
                    success = parser.insert_to_bigquery(
                        announcement_id,
                        text,
                        result['items'],
                        file_path,
                        pattern,
                        confidence
                    )
                    
                    if success:
                        print(f"  âœ… BigQueryæŠ•å…¥æˆåŠŸ")
                        stats['inserted'] += 1
                    else:
                        print(f"  âŒ BigQueryæŠ•å…¥å¤±æ•—")
            
            print()
        
        except Exception as e:
            print(f"  âŒ ä¾‹å¤–: {e}")
            stats['failed'] += 1
            stats['errors'].append({
                'file': file_path.name,
                'pattern': 'EXCEPTION',
                'error': str(e)
            })
            print()
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("=" * 70)
    print("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    print(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total']}")
    print(f"æˆåŠŸ: {stats['success']} ({stats['success']/stats['total']*100:.1f}%)")
    print(f"å¤±æ•—: {stats['failed']} ({stats['failed']/stats['total']*100:.1f}%)")
    if insert_to_bq:
        print(f"BigQueryæŠ•å…¥: {stats['inserted']} ({stats['inserted']/stats['total']*100:.1f}%)")
    print()
    
    print("ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥:")
    for pattern, count in sorted(stats['by_pattern'].items(), key=lambda x: x[1], reverse=True):
        print(f"  {pattern}: {count} ({count/stats['total']*100:.1f}%)")
    print()
    
    if stats['errors']:
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°ï¼ˆæœ€åˆã®5ä»¶ï¼‰:")
        for error in stats['errors'][:5]:
            print(f"  - {error['file']}: {error['error'][:50]}...")
        print()
    
    return stats


def test_universal_parser():
    """çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ã®ãƒ†ã‚¹ãƒˆï¼ˆ4ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"""
    
    print("=" * 70)
    print("Phase 5 çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    print()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_files = [
        Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20230915_ä»¤å’Œ5å¹´10æœˆ11æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬äºŒç™¾äº”åä¸€å·ï¼‰.txt"),
        Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20230414_ä»¤å’Œ5å¹´5æœˆ9æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬ç™¾äºŒåä¸ƒå·ï¼‰.txt"),
        Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20230615_ä»¤å’Œ5å¹´7æœˆ11æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬ç™¾ä¹åäºŒå·ï¼‰.txt"),
        Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023\20231211_ä»¤å’Œ6å¹´1æœˆ12æ—¥ä»˜ï¼ˆè²¡å‹™çœç¬¬åå…­å·ï¼‰.txt"),
    ]
    
    parser = UniversalAnnouncementParser()
    
    for file_path in test_files:
        if not file_path.exists():
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path.name}")
            continue
        
        print(f"ğŸ“„ {file_path.name}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
        
        result = parser.parse(text, file_path)
        
        print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³: {result['pattern']}")
        print(f"  ä¿¡é ¼åº¦: {result['confidence']:.2f}")
        
        if result['error']:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
        else:
            print(f"  âœ… ãƒ‘ãƒ¼ã‚¹æˆåŠŸï¼ˆ{len(result['items'])} é …ç›®ï¼‰")
        
        print()
    
    print("=" * 70)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 70)


if __name__ == "__main__":
    # çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ã®ãƒ†ã‚¹ãƒˆ
    test_universal_parser()
    
    print()
    print("=" * 70)
    print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. batch_process() ã§ãƒãƒƒãƒå‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆï¼ˆ10ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
    print("  2. BigQueryæŠ•å…¥ã®ãƒ†ã‚¹ãƒˆ")
    print("  3. å…¨ä»¶å‡¦ç†ï¼ˆ179ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
    print("=" * 70)