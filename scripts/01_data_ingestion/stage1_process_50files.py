"""
Phase 5 å…¨ä»¶å‡¦ç† - ã‚¹ãƒ†ãƒ¼ã‚¸1: æœ€åˆã®50ãƒ•ã‚¡ã‚¤ãƒ«

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€179ãƒ•ã‚¡ã‚¤ãƒ«ã®å…¨ä»¶å‡¦ç†ã‚’æ®µéšçš„ã«è¡Œã†ç¬¬ä¸€æ®µéšã§ã™ã€‚
æœ€åˆã®50ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ20251028ã«æŠ•å…¥ã—ã¾ã™ã€‚

å®Ÿè¡Œå‰ã®ç¢ºèªäº‹é …:
1. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ20251028ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨
2. raw_announcements ã¨ announcement_items ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨
3. çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼v5ãŒæ­£ã—ãé…ç½®ã•ã‚Œã¦ã„ã‚‹ã“ã¨

å®Ÿè¡Œå¾Œã®ç¢ºèªäº‹é …:
1. BigQueryã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§æŠ•å…¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
2. ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®åˆ†å¸ƒã‚’ç¢ºèª
3. ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°è©³ç´°ã‚’èª¿æŸ»
"""

from pathlib import Path
from datetime import datetime
import json

# çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# æ³¨: universal_announcement_parser_v5.pyã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã™ã‚‹ã“ã¨
import sys
sys.path.append(str(Path(__file__).parent))

from universal_announcement_parser_v5 import batch_process

# è¨­å®š
INPUT_DIR = Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\JGBãƒ‡ãƒ¼ã‚¿\2023")
DATASET_ID = "20251028"  # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
STAGE_NAME = "Stage 1"
MAX_FILES = 50

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®š
LOG_DIR = Path(__file__).parent / "logs"
LOG_DIR.mkdir(exist_ok=True)
TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")
LOG_FILE = LOG_DIR / f"stage1_processing_{TIMESTAMP}.json"

print("=" * 70)
print(f"Phase 5 å…¨ä»¶å‡¦ç† - {STAGE_NAME}")
print("=" * 70)
print(f"ğŸ“ å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {INPUT_DIR}")
print(f"ğŸ—„ï¸  ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆID: {DATASET_ID}")
print(f"ğŸ“Š å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {MAX_FILES}ãƒ•ã‚¡ã‚¤ãƒ«")
print(f"ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {LOG_FILE}")
print("=" * 70)
print()

# ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
print("âš ï¸  é‡è¦ãªç¢ºèªäº‹é …:")
print("  1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ20251028ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ")
print("  2. raw_announcements ãƒ†ãƒ¼ãƒ–ãƒ«ã¯å­˜åœ¨ã—ã¾ã™ã‹ï¼Ÿ")
print("  3. announcement_items ãƒ†ãƒ¼ãƒ–ãƒ«ã¯å­˜åœ¨ã—ã¾ã™ã‹ï¼Ÿ")
print()
input("æº–å‚™ãŒã§ããŸã‚‰Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
print()

# å‡¦ç†é–‹å§‹
print("ğŸš€ å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
print()

start_time = datetime.now()

# ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œ
stats = batch_process(
    input_dir=INPUT_DIR,
    dataset_id=DATASET_ID,
    test_mode=True,
    max_files=MAX_FILES,
    insert_to_bq=True
)

end_time = datetime.now()
duration = end_time - start_time

# çµæœã®ã‚µãƒãƒªãƒ¼
print()
print("=" * 70)
print("ğŸ“Š Stage 1 å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
print("=" * 70)
print(f"å‡¦ç†æ™‚é–“: {duration}")
print(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total']}")
print(f"æˆåŠŸ: {stats['success']} ({stats['success']/stats['total']*100:.1f}%)")
print(f"å¤±æ•—: {stats['failed']} ({stats['failed']/stats['total']*100:.1f}%)")
print(f"BigQueryæŠ•å…¥: {stats['inserted']} ({stats['inserted']/stats['total']*100:.1f}%)")
print()

print("ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®åˆ†å¸ƒ:")
for pattern, count in sorted(stats['by_pattern'].items(), key=lambda x: x[1], reverse=True):
    print(f"  {pattern}: {count} ({count/stats['total']*100:.1f}%)")
print()

if stats['errors']:
    print(f"âš ï¸  ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(stats['errors'])}ä»¶")
    print("è©³ç´°:")
    for error in stats['errors']:
        print(f"  - {error['file']}")
        print(f"    ãƒ‘ã‚¿ãƒ¼ãƒ³: {error['pattern']}")
        print(f"    ã‚¨ãƒ©ãƒ¼: {error['error'][:100]}...")
    print()

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
log_data = {
    'stage': STAGE_NAME,
    'dataset_id': DATASET_ID,
    'start_time': start_time.isoformat(),
    'end_time': end_time.isoformat(),
    'duration_seconds': duration.total_seconds(),
    'stats': stats
}

with open(LOG_FILE, 'w', encoding='utf-8') as f:
    json.dump(log_data, f, ensure_ascii=False, indent=2)

print(f"ğŸ“ è©³ç´°ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {LOG_FILE}")
print()

# æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®æ¡ˆå†…
print("=" * 70)
print("âœ… Stage 1 å®Œäº†")
print("=" * 70)
print()
print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
print("1. BigQueryã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
print()
print("   -- æŠ•å…¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª")
print("   SELECT ")
print("     announcement_id,")
print("     announcement_date,")
print("     issue_date,")
print("     format_pattern,")
print("     format_pattern_confidence")
print("   FROM `jgb2023.20251028.raw_announcements`")
print("   WHERE issue_date >= DATE('2023-01-01')")
print("   ORDER BY announcement_date DESC")
print("   LIMIT 20;")
print()
print("2. ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®ä»¶æ•°ã‚’ç¢ºèª:")
print()
print("   SELECT ")
print("     format_pattern,")
print("     COUNT(*) as count")
print("   FROM `jgb2023.20251028.raw_announcements`")
print("   WHERE issue_date >= DATE('2023-01-01')")
print("   GROUP BY format_pattern")
print("   ORDER BY count DESC;")
print()

if stats['failed'] == 0:
    print("3. ã‚¨ãƒ©ãƒ¼ãŒãªã‹ã£ãŸã®ã§ã€Stage 2ã«é€²ã‚€ã“ã¨ãŒã§ãã¾ã™")
    print("   stage2_process_50files.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
else:
    print("3. ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„")
    print("   å•é¡Œã‚’è§£æ±ºã—ã¦ã‹ã‚‰æ¬¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã«é€²ã‚“ã§ãã ã•ã„")

print()
print("=" * 70)