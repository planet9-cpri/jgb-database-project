"""
Phase 5 çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ v7: å®Œå…¨ç‰ˆ
ğŸ”§ ä¿®æ­£å†…å®¹:
  1. and/or å„ªå…ˆé †ä½ã®ä¿®æ­£ï¼ˆå®Œäº†ï¼‰
  2. ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–åŸºç›¤ã®å®Ÿè£…ï¼ˆå®Œäº†ï¼‰
  3. ãƒ‘ãƒ¼ã‚µãƒ¼ç²¾åº¦ã®å‘ä¸Šï¼ˆæ–°è¦ï¼‰
     - TableParserV4ã®æ­£è¦è¡¨ç¾æ”¹å–„
     - ã€ŒåŒæ³•ã€å‚ç…§ãƒ­ã‚¸ãƒƒã‚¯ã®æ”¹å–„
     - é˜²å¾¡çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°
  4. å…¨ãƒ‘ãƒ¼ã‚µãƒ¼ã®æ­£è¦åŒ–å¯¾å¿œï¼ˆå®Œäº†ï¼‰
"""

import re
import json
import unicodedata
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
import os
from google.cloud import bigquery

# BigQueryèªè¨¼æƒ…å ±ã®è¨­å®šï¼ˆæœ¬ç•ªç’°å¢ƒã§ã¯ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼‰
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'C:\Users\sonke\secrets\jgb2023-f8c9b849ae2d.json'

PROJECT_ID = "jgb2023"
DATASET_ID = "20251028"


# =============================================================================
# æ­£è¦åŒ–åŸºç›¤
# =============================================================================

CIRCLED_NUMBERS = {
    'â‘´': '(1)', 'â‘µ': '(2)', 'â‘¶': '(3)', 'â‘·': '(4)', 'â‘¸': '(5)',
    'â‘ ': '(1)', 'â‘¡': '(2)', 'â‘¢': '(3)', 'â‘£': '(4)', 'â‘¤': '(5)',
    'ï¼ˆï¼‘ï¼‰': '(1)', 'ï¼ˆï¼’ï¼‰': '(2)', 'ï¼ˆï¼“ï¼‰': '(3)', 'ï¼ˆï¼”ï¼‰': '(4)', 'ï¼ˆï¼•ï¼‰': '(5)',
    '(ï¼‘)': '(1)', '(ï¼’)': '(2)', '(ï¼“)': '(3)', '(ï¼”)': '(4)', '(ï¼•)': '(5)',
}

KANJI_NUMBERS = {
    'ã€‡': '0', 'é›¶': '0',
    'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5',
    'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9', 'å': '10',
    'å…ƒ': '1',
}


def normalize_text(text: str) -> str:
    """å‘Šç¤ºãƒ†ã‚­ã‚¹ãƒˆã‚’æ¨™æº–å½¢å¼ã«æ­£è¦åŒ–"""
    # Unicodeæ­£è¦åŒ–ï¼ˆNFKCï¼‰
    text = unicodedata.normalize('NFKC', text)
    
    # ä¸¸æ•°å­—ã¨å…¨è§’æ‹¬å¼§ã®çµ±ä¸€
    for original, normalized in CIRCLED_NUMBERS.items():
        text = text.replace(original, normalized)
    
    # æ¼¢æ•°å­—ã®å¤‰æ›
    for kanji, digit in KANJI_NUMBERS.items():
        text = text.replace(kanji, digit)
    
    # ç©ºç™½æ–‡å­—ã®çµ±ä¸€
    text = re.sub(r'[ \t\u3000]+', ' ', text)
    
    return text


def parse_japanese_date(text: str) -> Optional[str]:
    """
    å’Œæš¦ã‚’è¥¿æš¦ã«å¤‰æ›
    ä»¤å’Œã€å¹³æˆã€æ˜­å’Œã«å¯¾å¿œ
    """
    ERA_BASE_YEARS = {'ä»¤å’Œ': 2018, 'å¹³æˆ': 1988, 'æ˜­å’Œ': 1925}
    
    match = re.search(r'(ä»¤å’Œ|å¹³æˆ|æ˜­å’Œ)(\d+)å¹´(\d+)æœˆ(\d+)æ—¥', text)
    if not match:
        return None
    
    era = match.group(1)
    year = int(match.group(2)) + ERA_BASE_YEARS[era]
    month = int(match.group(3))
    day = int(match.group(4))
    
    return f'{year}-{month:02d}-{day:02d}'


def safe_extract_amount(text: str) -> Optional[int]:
    """
    é‡‘é¡ã‚’å®‰å…¨ã«æŠ½å‡ºï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œï¼‰
    """
    patterns = [
        r'é¡é¢é‡‘é¡ã§([\d,]+)å††',
        r'é¡é¢é‡‘é¡([\d,]+)å††',
        r'é‡‘é¡([\d,]+)å††',
        r'([\d,]+)å††',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            try:
                amount_str = match.group(1).replace(',', '')
                return int(amount_str)
            except (ValueError, AttributeError):
                continue
    
    return None


# =============================================================================
# NumberedListParser (æ”¹å–„ç‰ˆ)
# =============================================================================

class NumberedListParser:
    """ç•ªå·ä»˜ããƒªã‚¹ãƒˆå½¢å¼ã®ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢"""
        score = 0.0
        
        if 'å›½åº«çŸ­æœŸè¨¼åˆ¸' in text or 'å‰²å¼•çŸ­æœŸå›½å‚µ' in text or 'æ”¿åºœçŸ­æœŸè¨¼åˆ¸' in text:
            return 0.1
        
        has_item1 = bool(re.search(r'\b1\s+åç§°åŠã³è¨˜å·', text))
        has_item2 = bool(re.search(r'\b2\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹', text))
        has_item_amount = bool(re.search(r'\b[56]\s+.*?ç™º.*?è¡Œ.*?é¡', text))
        
        if has_item1 and has_item2 and has_item_amount:
            score += 0.4
        
        if 'ä¾¡æ ¼ç«¶äº‰å…¥æœ­' in text and 'éä¾¡æ ¼ç«¶äº‰å…¥æœ­' in text:
            score += 0.3
        
        if 'ä¸¦ã³ã«' in text and 'åŠã³' in text:
            score += 0.2
        
        if '(åˆ¥è¡¨ã®ã¨ãŠã‚Š)' not in text and 'åˆ¥è¡¨' not in text:
            score += 0.3
        
        return min(score, 1.0)
    
    def extract(self, text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·
        match = re.search(r'\b1\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\n2\b)', text, re.DOTALL)
        if match:
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item1(match.group(1))
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹
        match = re.search(r'\b2\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\n3\b)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item2(match.group(1))
            }
        
        # é …ç›®6: ç™ºè¡Œé¡
        match = re.search(r'\b6\s+ç™ºè¡Œé¡(.+?)(?=\n7\b)', text, re.DOTALL)
        if match:
            full_text = match.group(1).strip()
            items[6] = {
                'title': 'ç™ºè¡Œé¡',
                'value': full_text,
                'sub_number': None,
                'structured_data': self._parse_item6(full_text)
            }
            
            # ã‚µãƒ–é …ç›®ã‚‚æŠ½å‡º
            sub_items = self._extract_sub_items(full_text)
            for sub_num, sub_data in sub_items.items():
                items[f'6_{sub_num}'] = {
                    'title': 'ç™ºè¡Œé¡ã‚µãƒ–é …ç›®',
                    'value': sub_data['value'],
                    'sub_number': sub_num,
                    'structured_data': sub_data['structured']
                }
        
        # é …ç›®10: ç™ºè¡Œæ—¥
        match = re.search(r'\b10\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\n11\b)', text, re.DOTALL)
        if match:
            items[10] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'issue_date': parse_japanese_date(match.group(1))}
            }
        
        # é …ç›®12: åˆ©ç‡
        match = re.search(r'\b12\s+åˆ©ç‡\s+(.+?)(?=\n13\b)', text, re.DOTALL)
        if match:
            items[12] = {
                'title': 'åˆ©ç‡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_rate(match.group(1))
            }
        
        # é …ç›®16: å„Ÿé‚„æœŸé™
        match = re.search(r'\b16\s+å„Ÿé‚„æœŸé™\s+(.+?)(?=\n17\b)', text, re.DOTALL)
        if match:
            items[16] = {
                'title': 'å„Ÿé‚„æœŸé™',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'maturity_date': parse_japanese_date(match.group(1))}
            }
        
        # é …ç›®17: å„Ÿé‚„é‡‘é¡
        match = re.search(r'\b17\s+å„Ÿé‚„é‡‘é¡\s+(.+?)(?=\n18\b)', text, re.DOTALL)
        if match:
            items[17] = {
                'title': 'å„Ÿé‚„é‡‘é¡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_redemption_amount(match.group(1))
            }
        
        return {'pattern': 'NUMBERED_LIST_MULTI_LAW', 'items': items}
    
    def _extract_sub_items(self, text: str) -> dict:
        """(1)(2)(3)ã®ã‚µãƒ–é …ç›®ã‚’æŠ½å‡º"""
        sub_items = {}
        
        match1 = re.search(r'\(1\)\s*ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)(?=\(2\)|$)', text, re.DOTALL)
        if match1:
            sub_items[1] = {
                'value': f'(1) ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match1.group(1).strip()}',
                'structured': self._parse_section_with_context(match1.group(1))
            }
        
        match2 = re.search(r'\(2\)\s*å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€….*?ç¬¬Iéä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)(?=\(3\)|$)', text, re.DOTALL)
        if match2:
            sub_items[2] = {
                'value': f'(2) ç¬¬Iéä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match2.group(1).strip()}',
                'structured': self._parse_section_with_context(match2.group(1))
            }
        
        match3 = re.search(r'\(3\)\s*å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€….*?ç¬¬IIéä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)$', text, re.DOTALL)
        if match3:
            sub_items[3] = {
                'value': f'(3) ç¬¬IIéä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match3.group(1).strip()}',
                'structured': self._parse_section_with_context(match3.group(1))
            }
        
        return sub_items
    
    def _parse_section_with_context(self, section_text: str) -> dict:
        """
        ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç‹¬ç«‹ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§è§£æ
        ğŸ”§ æ”¹å–„: last_law_nameã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³å˜ä½ã§ãƒªã‚»ãƒƒãƒˆ
        """
        result = {'total_amount': 0, 'by_law': {}}
        last_law_name = None  # ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³å°‚ç”¨
        
        # ç·é¡ã‚’æŠ½å‡º
        amount = safe_extract_amount(section_text)
        if amount:
            result['total_amount'] = amount
        
        # æ˜ç¤ºçš„ãªæ³•ä»¤åã®ãƒãƒƒãƒ
        law_matches = re.finditer(
            r'([^ã€]+ç¬¬\d+æ¡ç¬¬\d+é …)ã®è¦å®šã«åŸºã¥.*?é¡é¢é‡‘é¡(?:ã§)?([\d,]+)å††',
            section_text
        )
        
        for match in law_matches:
            law_ref = match.group(1).strip()
            amount = int(match.group(2).replace(',', ''))
            
            law_key = self._normalize_law_name(law_ref)
            if law_key:
                result['by_law'][law_key] = amount
                
                # ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã§ã®ç¾åœ¨ã®æ³•å¾‹ã‚’æ›´æ–°
                if 'ç‰¹åˆ¥ä¼šè¨ˆ' in law_ref:
                    last_law_name = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿é‹å–¶' in law_ref:
                    last_law_name = 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹'
                elif 'è²¡æ”¿æ³•' in law_ref:
                    last_law_name = 'è²¡æ”¿æ³•'
        
        # ã€ŒåŒæ³•ã€å‚ç…§ã‚’å‡¦ç†
        same_law_matches = re.finditer(
            r'åŒæ³•ç¬¬(\d+)æ¡ç¬¬(\d+)é …ã®è¦å®šã«åŸºã¥.*?é¡é¢é‡‘é¡(?:ã§)?([\d,]+)å††',
            section_text
        )
        
        for match in same_law_matches:
            article = match.group(1)
            paragraph = match.group(2)
            amount = int(match.group(3).replace(',', ''))
            
            if last_law_name:
                if last_law_name == 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹':
                    if article == '46':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'
                    elif article == '62':
                        law_key = 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …'
                    else:
                        law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                else:
                    law_key = f'{last_law_name}ç¬¬{article}æ¡ç¬¬{paragraph}é …'
                
                result['by_law'][law_key] = amount
            else:
                # è­¦å‘Š: å‚ç…§å…ˆä¸æ˜
                print(f"âš ï¸ 'åŒæ³•'å‚ç…§ãŒã‚ã‚‹ãŒå‚ç…§å…ˆãŒä¸æ˜: ç¬¬{article}æ¡ç¬¬{paragraph}é …")
                result['by_law'][f'ä¸æ˜ãªæ³•ä»¤_ç¬¬{article}æ¡ç¬¬{paragraph}é …'] = amount
        
        return result
    
    def _normalize_law_name(self, law_ref: str) -> str:
        """ğŸ”§ FIXED: æ‹¬å¼§ã§æ¡ä»¶ã®å„ªå…ˆé †ä½ã‚’æ˜ç¤º"""
        if 'è²¡æ”¿æ³•' in law_ref and 'ç¬¬4æ¡' in law_ref:
            return 'è²¡æ”¿æ³•ç¬¬4æ¡ç¬¬1é …'
        elif 'è²¡æ”¿é‹å–¶' in law_ref:
            return 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬3æ¡ç¬¬1é …'
        elif 'ç‰¹åˆ¥ä¼šè¨ˆ' in law_ref:
            if 'ç¬¬46æ¡' in law_ref:
                return 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'
            elif 'ç¬¬62æ¡' in law_ref:
                return 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …'
        return None
    
    def _parse_item1(self, text: str) -> dict:
        """é …ç›®1: åç§°åŠã³è¨˜å·"""
        match = re.search(r'åˆ©\s*ä»˜å›½åº«å‚µåˆ¸\((.+?)\)\(ç¬¬(\d+)å›\)', text)
        if match:
            return {
                'bond_name': f'åˆ©ä»˜å›½åº«å‚µåˆ¸({match.group(1)})',
                'bond_series': f'ç¬¬{match.group(2)}å›'
            }
        return {'raw': text}
    
    def _parse_item2(self, text: str) -> dict:
        """é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹"""
        laws = []
        
        if re.search(r'è²¡æ”¿æ³•.*?ç¬¬4æ¡ç¬¬1é …', text, re.DOTALL):
            laws.append({
                'name': 'è²¡æ”¿æ³•',
                'full_name': 'è²¡æ”¿æ³•(æ˜­å’Œ22å¹´æ³•å¾‹ç¬¬34å·)',
                'article': 'ç¬¬4æ¡ç¬¬1é …',
                'key': 'è²¡æ”¿æ³•ç¬¬4æ¡ç¬¬1é …',
                'amount': 0
            })
        
        if re.search(r'è²¡æ”¿é‹å–¶.*?ç¬¬3æ¡ç¬¬1é …', text, re.DOTALL):
            laws.append({
                'name': 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹(å¹³æˆ24å¹´æ³•å¾‹ç¬¬101å·)',
                'article': 'ç¬¬3æ¡ç¬¬1é …',
                'key': 'è²¡æ”¿é‹å–¶ã«å¿…è¦ãªè²¡æºã®ç¢ºä¿ã‚’å›³ã‚‹ãŸã‚ã®å…¬å‚µã®ç™ºè¡Œã®ç‰¹ä¾‹ã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬3æ¡ç¬¬1é …',
                'amount': 0
            })
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹(å¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·)',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬62æ¡ç¬¬1é …', text, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹(å¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·)',
                'article': 'ç¬¬62æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …',
                'amount': 0
            })
        
        return {'laws': laws}
    
    def _parse_item6(self, text: str) -> dict:
        """é …ç›®6: ç™ºè¡Œé¡"""
        result = {
            'total_amount': 0,
            'competitive': {'amount': 0, 'by_law': {}},
            'noncompetitive1': {'amount': 0, 'by_law': {}},
            'noncompetitive2': {'amount': 0, 'by_law': {}}
        }
        
        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç‹¬ç«‹ã—ã¦å‡¦ç†
        sections = [
            ('competitive', r'\(1\)(.+?)(?=\(2\)|$)'),
            ('noncompetitive1', r'\(2\)(.+?)(?=\(3\)|$)'),
            ('noncompetitive2', r'\(3\)(.+?)$')
        ]
        
        for section_name, pattern in sections:
            match = re.search(pattern, text, re.DOTALL)
            if match:
                parsed = self._parse_section_with_context(match.group(1))
                result[section_name] = parsed
                result['total_amount'] += parsed['total_amount']
        
        return result
    
    def _parse_rate(self, text: str) -> dict:
        """åˆ©ç‡ã‚’è§£æ"""
        match = re.search(r'å¹´\s*([\d.]+)\s*%', text)
        if match:
            return {'rate': float(match.group(1))}
        return {'raw': text}
    
    def _parse_redemption_amount(self, text: str) -> dict:
        """å„Ÿé‚„é‡‘é¡ã‚’è§£æ"""
        match = re.search(r'é¡é¢é‡‘é¡100å††ã«ã¤(\d+)å††', text)
        if match:
            return {'amount': int(match.group(1))}
        return {'raw': text}


# =============================================================================
# TableParserV4 (å¤§å¹…æ”¹å–„ç‰ˆ)
# =============================================================================

class TableParserV4:
    """æ¨ªä¸¦ã³åˆ¥è¡¨å½¢å¼ã®ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆå¤§å¹…æ”¹å–„ç‰ˆï¼‰"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢"""
        score = 0.0
        
        if '(åˆ¥è¡¨ã®ã¨ãŠã‚Š)' in text or 'å†…è¨³(åˆ¥è¡¨ã®ã¨ãŠã‚Š)' in text:
            score += 0.4
        
        if 'åç§°åŠã³è¨˜å·' in text and 'åˆ©ç‡' in text and 'å„Ÿé‚„æœŸé™' in text:
            score += 0.4
        
        if '(åˆ¥è¡¨)' in text:
            score += 0.2
        
        return min(score, 1.0)
    
    def extract(self, text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·
        match = re.search(r'\b1\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\n2\b)', text, re.DOTALL)
        if match:
            bond_names = self._parse_multiple_bond_names(match.group(1))
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'bond_names': bond_names}
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹
        match = re.search(r'\b2\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\n3\b)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_laws(match.group(1))
            }
        
        # é …ç›®6: ç™ºè¡Œé¡ï¼ˆåˆ¥è¡¨å‚ç…§ï¼‰
        match = re.search(r'\b6\s+ç™ºè¡Œé¡\s+é¡é¢é‡‘é¡(?:ã§)?([\d,]+)å††', text, re.DOTALL)
        if match:
            total_amount = int(match.group(1).replace(',', ''))
            items[6] = {
                'title': 'ç™ºè¡Œé¡',
                'value': f'é¡é¢é‡‘é¡ã§{match.group(1)}å††\nå†…è¨³(åˆ¥è¡¨ã®ã¨ãŠã‚Š)',
                'sub_number': None,
                'structured_data': {'total_amount': total_amount}
            }
        
        # é …ç›®10: ç™ºè¡Œæ—¥
        match = re.search(r'\b10\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\n11\b)', text, re.DOTALL)
        if match:
            items[10] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'issue_date': parse_japanese_date(match.group(1))}
            }
        
        # åˆ¥è¡¨ã®è§£æï¼ˆæ”¹å–„ç‰ˆï¼‰
        table_data = self._parse_table_robust(text)
        if table_data:
            for i, row in enumerate(table_data, start=1):
                items[f'6_{i}'] = {
                    'title': 'ç™ºè¡Œé¡(åˆ¥è¡¨)',
                    'value': self._format_table_row(row),
                    'sub_number': i,
                    'structured_data': row
                }
        
        return {'pattern': 'TABLE_HORIZONTAL', 'items': items}
    
    def _parse_table_robust(self, text: str) -> list:
        """
        è¡¨ã‚’å …ç‰¢ã«è§£æï¼ˆè¡Œåˆ†å‰²ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
        ğŸ”§ æ”¹å–„: è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œã€ã‚¹ãƒšãƒ¼ã‚¹ã‚„ã€Œåˆ†ã€ã®æœ‰ç„¡ã«è€æ€§
        """
        table_start = text.find('(åˆ¥è¡¨)')
        if table_start == -1:
            return []
        
        table_text = text[table_start:]
        rows = []
        
        # æ”¹å–„ã•ã‚ŒãŸæ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæŸ”è»Ÿæ€§å‘ä¸Šï¼‰
        pattern = (
            r'åˆ©ä»˜å›½åº«å‚µåˆ¸\((.+?)\)\s*'
            r'\(ç¬¬(\d+)å›\)\s+'
            r'([\d.]+)%\s+'
            r'(?:ä»¤å’Œ|å¹³æˆ)(\d+)å¹´(\d+)æœˆ(\d+)æ—¥\s+'
            r'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬(\d+)æ¡ç¬¬1é …(?:åˆ†)?\s+'
            r'([\d,]+)å††'
        )
        
        matches = re.finditer(pattern, table_text)
        
        for match in matches:
            bond_type = match.group(1)
            series = match.group(2)
            rate = float(match.group(3))
            
            # å…ƒå·åˆ¤å®š
            if 'ä»¤å’Œ' in match.group(0):
                year = int(match.group(4)) + 2018
            else:  # å¹³æˆ
                year = int(match.group(4)) + 1988
            
            month = int(match.group(5))
            day = int(match.group(6))
            law_article = match.group(7)
            amount = int(match.group(8).replace(',', ''))
            
            law_key = f'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬{law_article}æ¡ç¬¬1é …'
            
            row = {
                'bond_name': f'åˆ©ä»˜å›½åº«å‚µåˆ¸({bond_type})',
                'bond_series': f'ç¬¬{series}å›',
                'interest_rate': rate,
                'maturity_date': f'{year}-{month:02d}-{day:02d}',
                'law_key': law_key,
                'law_article': f'ç¬¬{law_article}æ¡ç¬¬1é …',
                'issue_amount': amount
            }
            
            rows.append(row)
        
        return rows
    
    def _parse_multiple_bond_names(self, text: str) -> list:
        """è¤‡æ•°ã®éŠ˜æŸ„åã‚’æŠ½å‡º"""
        bond_names = []
        parts = re.split(r'åŠã³', text)
        
        for part in parts:
            part = part.strip()
            if 'åˆ©ä»˜å›½åº«å‚µåˆ¸' in part:
                bond_names.append(part)
        
        return bond_names
    
    def _parse_laws(self, text: str) -> dict:
        """æ³•ä»¤ã‚’æŠ½å‡º"""
        laws = []
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹(å¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·)',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬62æ¡ç¬¬1é …', text, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹(å¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·)',
                'article': 'ç¬¬62æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬62æ¡ç¬¬1é …',
                'amount': 0
            })
        
        return {'laws': laws}
    
    def _format_table_row(self, row: dict) -> str:
        """è¡¨ã®è¡Œã‚’æ–‡å­—åˆ—ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return (f"{row['bond_name']}{row['bond_series']}: "
                f"åˆ©ç‡{row['interest_rate']}%, "
                f"å„Ÿé‚„æœŸé™{row['maturity_date']}, "
                f"{row['law_key']}, "
                f"ç™ºè¡Œé¡{row['issue_amount']:,}å††")


# =============================================================================
# RetailBondParser (æ­£è¦åŒ–å¯¾å¿œç‰ˆ)
# =============================================================================

class RetailBondParser:
    """å€‹äººå‘ã‘å›½å‚µã®ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆæ­£è¦åŒ–å¯¾å¿œç‰ˆï¼‰"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢"""
        if 'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸' in text or 'å€‹äººå‘ã‘å›½å‚µ' in text:
            return 1.0
        return 0.0
    
    def extract(self, text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·
        match = re.search(r'\b1\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\n2\b)', text, re.DOTALL)
        if match:
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item1(match.group(1))
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹
        match = re.search(r'\b2\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\n3\b)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_laws(match.group(1))
            }
        
        # é …ç›®4: ç™ºè¡Œé¡ï¼ˆå€‹äººå‘ã‘ã¯é …ç›®4ï¼‰
        match = re.search(r'\b4\s+ç™ºè¡Œé¡\s+é¡é¢é‡‘é¡(?:ã§)?([\d,]+)å††', text, re.DOTALL)
        if match:
            total_amount = int(match.group(1).replace(',', ''))
            items[4] = {
                'title': 'ç™ºè¡Œé¡',
                'value': f'é¡é¢é‡‘é¡ã§{match.group(1)}å††',
                'sub_number': None,
                'structured_data': {'total_amount': total_amount}
            }
        
        # é …ç›®7: ç™ºè¡Œæ—¥ï¼ˆå€‹äººå‘ã‘ã¯é …ç›®7ï¼‰
        match = re.search(r'\b7\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\n8\b)', text, re.DOTALL)
        if match:
            items[7] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'issue_date': parse_japanese_date(match.group(1))}
            }
        
        # é …ç›®9: åˆæœŸåˆ©å­ã®é©ç”¨åˆ©ç‡
        match = re.search(r'\b9\s+åˆæœŸåˆ©å­ã®é©ç”¨åˆ©ç‡\s+å¹´\s*([\d.]+)\s*%', text, re.DOTALL)
        if match:
            items[9] = {
                'title': 'åˆæœŸåˆ©å­ã®é©ç”¨åˆ©ç‡',
                'value': f'å¹´{match.group(1)}%',
                'sub_number': None,
                'structured_data': {'rate': float(match.group(1))}
            }
        
        # é …ç›®13: å„Ÿé‚„æœŸé™
        match = re.search(r'\b13\s+å„Ÿé‚„æœŸé™\s+(.+?)(?=\n14\b)', text, re.DOTALL)
        if match:
            items[13] = {
                'title': 'å„Ÿé‚„æœŸé™',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'maturity_date': parse_japanese_date(match.group(1))}
            }
        
        # é …ç›®14: å„Ÿé‚„é‡‘é¡
        match = re.search(r'\b14\s+å„Ÿé‚„é‡‘é¡\s+(.+?)(?=\n15\b)', text, re.DOTALL)
        if match:
            items[14] = {
                'title': 'å„Ÿé‚„é‡‘é¡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_redemption_amount(match.group(1))
            }
        
        return {'pattern': 'RETAIL_BOND', 'items': items}
    
    def _parse_item1(self, text: str) -> dict:
        """é …ç›®1: åç§°åŠã³è¨˜å·"""
        match = re.search(r'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸\((.+?)\)\(ç¬¬(\d+)å›\)', text)
        if match:
            return {
                'bond_name': f'å€‹äººå‘ã‘åˆ©ä»˜å›½åº«å‚µåˆ¸({match.group(1)})',
                'bond_series': f'ç¬¬{match.group(2)}å›',
                'bond_type': match.group(1)
            }
        return {'raw': text}
    
    def _parse_laws(self, text: str) -> dict:
        """æ³•ä»¤ã‚’æŠ½å‡º"""
        laws = []
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹(å¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·)',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        
        return {'laws': laws}
    
    def _parse_redemption_amount(self, text: str) -> dict:
        """å„Ÿé‚„é‡‘é¡ã‚’è§£æ"""
        match = re.search(r'é¡é¢é‡‘é¡100å††ã«ã¤(\d+)å††', text)
        if match:
            return {'amount': int(match.group(1))}
        return {'raw': text}


# =============================================================================
# TBParser (æ­£è¦åŒ–å¯¾å¿œç‰ˆ)
# =============================================================================

class TBParser:
    """å›½åº«çŸ­æœŸè¨¼åˆ¸ã®ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆæ­£è¦åŒ–å¯¾å¿œç‰ˆï¼‰"""
    
    def can_parse(self, text: str) -> float:
        """å‡¦ç†å¯èƒ½æ€§ã‚¹ã‚³ã‚¢"""
        score = 0.0
        
        if 'å›½åº«çŸ­æœŸè¨¼åˆ¸' in text:
            score += 0.5
        
        if 'å‰²å¼•çŸ­æœŸå›½å‚µ' in text or 'æ”¿åºœçŸ­æœŸè¨¼åˆ¸' in text:
            score += 0.5
        
        return min(score, 1.0)
    
    def extract(self, text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        items = {}
        
        # é …ç›®1: åç§°åŠã³è¨˜å·
        match = re.search(r'\b1\s+åç§°åŠã³è¨˜å·\s+(.+?)(?=\n2\b)', text, re.DOTALL)
        if match:
            items[1] = {
                'title': 'åç§°åŠã³è¨˜å·',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_item1(match.group(1))
            }
        
        # é …ç›®2: ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹
        match = re.search(r'\b2\s+ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …\s+(.+?)(?=\n3\b)', text, re.DOTALL)
        if match:
            items[2] = {
                'title': 'ç™ºè¡Œã®æ ¹æ‹ æ³•å¾‹åŠã³ãã®æ¡é …',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_laws(match.group(1))
            }
        
        # é …ç›®6: ç™ºè¡Œé¡
        match = re.search(r'\b6\s+ç™ºè¡Œé¡(.+?)(?=\n7\b)', text, re.DOTALL)
        if match:
            full_text = match.group(1).strip()
            items[6] = {
                'title': 'ç™ºè¡Œé¡',
                'value': full_text,
                'sub_number': None,
                'structured_data': self._parse_item6(full_text)
            }
            
            # ã‚µãƒ–é …ç›®ã‚‚æŠ½å‡º
            sub_items = self._extract_sub_items(full_text)
            for sub_num, sub_data in sub_items.items():
                items[f'6_{sub_num}'] = {
                    'title': 'ç™ºè¡Œé¡ã‚µãƒ–é …ç›®',
                    'value': sub_data['value'],
                    'sub_number': sub_num,
                    'structured_data': sub_data['structured']
                }
        
        # é …ç›®10: ç™ºè¡Œæ—¥
        match = re.search(r'\b10\s+ç™ºè¡Œæ—¥\s+(.+?)(?=\n11\b)', text, re.DOTALL)
        if match:
            items[10] = {
                'title': 'ç™ºè¡Œæ—¥',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'issue_date': parse_japanese_date(match.group(1))}
            }
        
        # é …ç›®12: å„Ÿé‚„æœŸé™
        match = re.search(r'\b12\s+å„Ÿé‚„æœŸé™\s+(.+?)(?=\n13\b)', text, re.DOTALL)
        if match:
            items[12] = {
                'title': 'å„Ÿé‚„æœŸé™',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': {'maturity_date': parse_japanese_date(match.group(1))}
            }
        
        # é …ç›®13: å„Ÿé‚„é‡‘é¡
        match = re.search(r'\b13\s+å„Ÿé‚„é‡‘é¡\s+(.+?)(?=\n14\b)', text, re.DOTALL)
        if match:
            items[13] = {
                'title': 'å„Ÿé‚„é‡‘é¡',
                'value': match.group(1).strip(),
                'sub_number': None,
                'structured_data': self._parse_redemption_amount(match.group(1))
            }
        
        return {'pattern': 'TB_SHORT_TERM', 'items': items}
    
    def _extract_sub_items(self, text: str) -> dict:
        """(1)(2)ã®ã‚µãƒ–é …ç›®ã‚’æŠ½å‡º"""
        sub_items = {}
        
        match1 = re.search(r'\(1\)\s*ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)(?=\(2\)|$)', text, re.DOTALL)
        if match1:
            sub_items[1] = {
                'value': f'(1) ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match1.group(1).strip()}',
                'structured': self._parse_section_with_context(match1.group(1))
            }
        
        match2 = re.search(r'\(2\)\s*å›½å‚µå¸‚å ´ç‰¹åˆ¥å‚åŠ è€….*?ç¬¬Iéä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ(.+?)$', text, re.DOTALL)
        if match2:
            sub_items[2] = {
                'value': f'(2) ç¬¬Iéä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ{match2.group(1).strip()}',
                'structured': self._parse_section_with_context(match2.group(1))
            }
        
        return sub_items
    
    def _parse_section_with_context(self, section_text: str) -> dict:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç‹¬ç«‹ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§è§£æ"""
        result = {'total_amount': 0, 'by_law': {}}
        
        # ç·é¡ã‚’æŠ½å‡º
        amount = safe_extract_amount(section_text)
        if amount:
            result['total_amount'] = amount
        
        # å‰²å¼•çŸ­æœŸå›½å‚µ
        tb_match = re.search(r'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é ….*?å‰²å¼•çŸ­æœŸå›½å‚µ.*?é¡é¢é‡‘é¡(?:ã§)?([\d,]+)å††', section_text, re.DOTALL)
        if tb_match:
            amount = int(tb_match.group(1).replace(',', ''))
            result['by_law']['ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …'] = amount
        
        # æ”¿åºœçŸ­æœŸè¨¼åˆ¸
        gsb_match = re.search(r'è²¡æ”¿æ³•ç¬¬7æ¡ç¬¬1é ….*?æ”¿åºœçŸ­æœŸè¨¼åˆ¸.*?é¡é¢é‡‘é¡(?:ã§)?([\d,]+)å††', section_text, re.DOTALL)
        if gsb_match:
            amount = int(gsb_match.group(1).replace(',', ''))
            result['by_law']['æ”¿åºœçŸ­æœŸè¨¼åˆ¸é–¢é€£æ³•ä»¤'] = amount
        
        return result
    
    def _parse_item1(self, text: str) -> dict:
        """é …ç›®1: åç§°åŠã³è¨˜å·"""
        match = re.search(r'å›½åº«çŸ­æœŸè¨¼åˆ¸\(ç¬¬(\d+)å›\)', text)
        if match:
            return {
                'bond_name': 'å›½åº«çŸ­æœŸè¨¼åˆ¸',
                'bond_series': f'ç¬¬{match.group(1)}å›'
            }
        return {'raw': text}
    
    def _parse_laws(self, text: str) -> dict:
        """æ³•ä»¤ã‚’æŠ½å‡º"""
        laws = []
        
        if re.search(r'ç‰¹åˆ¥ä¼šè¨ˆ.*?ç¬¬46æ¡ç¬¬1é …', text, re.DOTALL):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹(å¹³æˆ19å¹´æ³•å¾‹ç¬¬23å·)',
                'article': 'ç¬¬46æ¡ç¬¬1é …',
                'key': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹ç¬¬46æ¡ç¬¬1é …',
                'amount': 0
            })
        
        tb_articles = ['83', '94', '95', '136', '137']
        if any(f'ç¬¬{a}æ¡' in text for a in tb_articles):
            laws.append({
                'name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹(æ”¿åºœçŸ­æœŸè¨¼åˆ¸)',
                'full_name': 'ç‰¹åˆ¥ä¼šè¨ˆã«é–¢ã™ã‚‹æ³•å¾‹(è¤‡æ•°æ¡é …)',
                'article': 'ç¬¬83æ¡ç­‰',
                'key': 'æ”¿åºœçŸ­æœŸè¨¼åˆ¸é–¢é€£æ³•ä»¤',
                'amount': 0
            })
        
        return {'laws': laws}
    
    def _parse_item6(self, text: str) -> dict:
        """é …ç›®6: ç™ºè¡Œé¡"""
        result = {
            'total_amount': 0,
            'competitive': {'amount': 0, 'by_law': {}},
            'noncompetitive1': {'amount': 0, 'by_law': {}}
        }
        
        # (1) ä¾¡æ ¼ç«¶äº‰å…¥æœ­
        comp_match = re.search(r'\(1\)\s*ä¾¡æ ¼ç«¶äº‰å…¥æœ­ç™ºè¡Œ\s*é¡é¢é‡‘é¡(?:ã§)?([\d,]+)å††', text)
        if comp_match:
            amount = int(comp_match.group(1).replace(',', ''))
            result['competitive']['amount'] = amount
            result['total_amount'] += amount
            
            comp_section = re.search(r'\(1\)(.+?)(?=\(2\)|$)', text, re.DOTALL)
            if comp_section:
                result['competitive']['by_law'] = self._parse_section_with_context(comp_section.group(1))['by_law']
        
        # (2) ç¬¬Iéä¾¡æ ¼ç«¶äº‰
        nc1_match = re.search(r'\(2\).*?é¡é¢é‡‘é¡(?:ã§)?([\d,]+)å††', text, re.DOTALL)
        if nc1_match:
            amount = int(nc1_match.group(1).replace(',', ''))
            result['noncompetitive1']['amount'] = amount
            result['total_amount'] += amount
            
            nc1_section = re.search(r'\(2\)(.+?)$', text, re.DOTALL)
            if nc1_section:
                result['noncompetitive1']['by_law'] = self._parse_section_with_context(nc1_section.group(1))['by_law']
        
        return result
    
    def _parse_redemption_amount(self, text: str) -> dict:
        """å„Ÿé‚„é‡‘é¡ã‚’è§£æ"""
        match = re.search(r'é¡é¢é‡‘é¡100å††ã«ã¤(\d+)å††', text)
        if match:
            return {'amount': int(match.group(1))}
        return {'raw': text}


# =============================================================================
# UniversalAnnouncementParser (å®Œå…¨ç‰ˆ)
# =============================================================================

class UniversalAnnouncementParser:
    """çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ v7: å®Œå…¨ç‰ˆ"""
    
    def __init__(self):
        # 4ã¤ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’å„ªå…ˆé †ä½é †ã«ç™»éŒ²
        self.parsers = [
            ('RETAIL_BOND', RetailBondParser()),
            ('TABLE_HORIZONTAL', TableParserV4()),
            ('TB_SHORT_TERM', TBParser()),
            ('NUMBERED_LIST_MULTI_LAW', NumberedListParser()),
        ]
        
        self.client = bigquery.Client(project=PROJECT_ID)
    
    def parse(self, text: str, file_path: Optional[Path] = None) -> Dict[str, Any]:
        """å‘Šç¤ºã‚’è§£æ"""
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–
            normalized_text = normalize_text(text)
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥
            pattern, confidence = self.identify_pattern(normalized_text)
            
            if confidence < 0.5:
                return {
                    'pattern': 'UNKNOWN',
                    'confidence': confidence,
                    'items': {},
                    'error': f'ãƒ‘ã‚¿ãƒ¼ãƒ³è­˜åˆ¥ã®ä¿¡é ¼åº¦ãŒä½ã„({confidence:.2f})',
                    'file_path': str(file_path) if file_path else None
                }
            
            # é©åˆ‡ãªãƒ‘ãƒ¼ã‚µãƒ¼ã‚’é¸æŠ
            parser = None
            for p_name, p in self.parsers:
                if p_name == pattern:
                    parser = p
                    break
            
            if parser is None:
                return {
                    'pattern': pattern,
                    'confidence': confidence,
                    'items': {},
                    'error': f'ãƒ‘ãƒ¼ã‚µãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}',
                    'file_path': str(file_path) if file_path else None
                }
            
            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            result = parser.extract(normalized_text)
            
            return {
                'pattern': result['pattern'],
                'confidence': confidence,
                'items': result.get('items', {}),
                'error': None,
                'file_path': str(file_path) if file_path else None
            }
        
        except Exception as e:
            return {
                'pattern': 'ERROR',
                'confidence': 0.0,
                'items': {},
                'error': str(e),
                'file_path': str(file_path) if file_path else None
            }
    
    def identify_pattern(self, text: str) -> Tuple[str, float]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•è­˜åˆ¥"""
        scores = {}
        
        for pattern_name, parser in self.parsers:
            score = parser.can_parse(text)
            scores[pattern_name] = score
        
        best_pattern = max(scores.items(), key=lambda x: x[1])
        return best_pattern[0], best_pattern[1]
    
    def extract_metadata_from_filename(self, file_path: Path) -> Dict[str, str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        filename = file_path.stem
        
        match = re.match(r'(\d{8})_ä»¤å’Œ(\d+)å¹´(\d+)æœˆ(\d+)æ—¥ä»˜\(è²¡å‹™çœ(.+?)\)', filename)
        
        if match:
            file_date = match.group(1)
            reiwa_year = int(match.group(2))
            month = int(match.group(3))
            day = int(match.group(4))
            announcement_num = match.group(5)
            
            announcement_year = reiwa_year + 2018
            announcement_date = f'{announcement_year}-{month:02d}-{day:02d}'
            
            return {
                'file_date': file_date,
                'announcement_date': announcement_date,
                'announcement_number': announcement_num
            }
        
        return {
            'file_date': 'unknown',
            'announcement_date': 'unknown',
            'announcement_number': 'unknown'
        }
    
    def insert_to_bigquery(
        self,
        announcement_id: str,
        raw_text: str,
        items: dict,
        file_path: Path,
        pattern: str,
        confidence: float
    ) -> bool:
        """BigQueryã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥"""
        
        try:
            metadata = self.extract_metadata_from_filename(file_path)
            
            # ç™ºè¡Œæ—¥ã‚’æŠ½å‡º
            issue_date = None
            if 10 in items:
                issue_date = items[10].get('structured_data', {}).get('issue_date')
            elif 7 in items:
                issue_date = items[7].get('structured_data', {}).get('issue_date')
            
            if not issue_date:
                issue_date = metadata['announcement_date']
            
            # Layer 1: raw_announcements
            raw_row = {
                'announcement_id': announcement_id,
                'announcement_date': metadata['announcement_date'],
                'announcement_number': metadata['announcement_number'],
                'issue_date': issue_date,
                'format_pattern': pattern,
                'format_pattern_confidence': confidence,
                'raw_text': raw_text,
                'source_file': file_path.name,
                'file_path': str(file_path),
                'parsed': True,
                'parse_error': None,
                'parsed_at': datetime.now().isoformat()
            }
            
            table_ref = f"{PROJECT_ID}.{DATASET_ID}.raw_announcements"
            errors = self.client.insert_rows_json(table_ref, [raw_row])
            
            if errors:
                print(f"  âœ— Layer 1 æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
                return False
            
            # Layer 2: announcement_items
            item_rows = []
            for key, item_data in items.items():
                if isinstance(key, str) and '_' in key:
                    parts = key.split('_')
                    item_number = int(parts[0])
                    sub_number = int(parts[1])
                else:
                    item_number = int(key)
                    sub_number = item_data.get('sub_number')
                
                item_row = {
                    'item_id': f"{announcement_id}_item{key}",
                    'announcement_id': announcement_id,
                    'item_number': item_number,
                    'sub_number': sub_number,
                    'item_title': item_data['title'],
                    'item_value': item_data['value'],
                    'structured_data': json.dumps(item_data['structured_data'], ensure_ascii=False)
                }
                item_rows.append(item_row)
            
            table_ref = f"{PROJECT_ID}.{DATASET_ID}.announcement_items"
            errors = self.client.insert_rows_json(table_ref, item_rows)
            
            if errors:
                print(f"  âœ— Layer 2 æŠ•å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
                return False
            
            return True
        
        except Exception as e:
            print(f"  âœ— BigQueryæŠ•å…¥ä¾‹å¤–: {e}")
            return False


def batch_process(
    input_dir: Path,
    dataset_id: str = DATASET_ID,
    test_mode: bool = True,
    max_files: int = 10,
    insert_to_bq: bool = True
) -> Dict[str, Any]:
    """ãƒãƒƒãƒå‡¦ç†: è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†"""
    
    parser = UniversalAnnouncementParser()
    files = sorted(input_dir.glob('*.txt'))
    
    if test_mode:
        files = files[:max_files]
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®{len(files)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
    else:
        print(f"ğŸš€ æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰: {len(files)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
    
    print(f"ğŸ“¤ BigQueryæŠ•å…¥: {'æœ‰åŠ¹' if insert_to_bq else 'ç„¡åŠ¹'}")
    print()
    
    stats = {
        'total': len(files),
        'success': 0,
        'failed': 0,
        'by_pattern': {},
        'errors': [],
        'inserted': 0
    }
    
    for i, file_path in enumerate(files, 1):
        print(f"[{i}/{len(files)}] {file_path.name}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            result = parser.parse(text, file_path)
            
            pattern = result['pattern']
            confidence = result['confidence']
            
            print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern} (ä¿¡é ¼åº¦: {confidence:.2f})")
            
            if pattern not in stats['by_pattern']:
                stats['by_pattern'][pattern] = 0
            stats['by_pattern'][pattern] += 1
            
            if result['error']:
                print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {result['error']}")
                stats['failed'] += 1
                stats['errors'].append({
                    'file': file_path.name,
                    'pattern': pattern,
                    'error': result['error']
                })
            else:
                print(f"  âœ“ ãƒ‘ãƒ¼ã‚¹æˆåŠŸ")
                stats['success'] += 1
                
                if insert_to_bq:
                    match = re.match(r'(\d{8})_.*\(è²¡å‹™çœ(.+?)\)', file_path.name)
                    if match:
                        date_part = match.group(1)
                        num_part = match.group(2).replace('ç¬¬', '').replace('å·', '')
                        announcement_id = f"{date_part}_{num_part}"
                    else:
                        announcement_id = file_path.stem
                    
                    success = parser.insert_to_bigquery(
                        announcement_id,
                        text,
                        result['items'],
                        file_path,
                        pattern,
                        confidence
                    )
                    
                    if success:
                        print(f"  âœ“ BigQueryæŠ•å…¥æˆåŠŸ")
                        stats['inserted'] += 1
                    else:
                        print(f"  âœ— BigQueryæŠ•å…¥å¤±æ•—")
            
            print()
        
        except Exception as e:
            print(f"  âœ— ä¾‹å¤–: {e}")
            stats['failed'] += 1
            stats['errors'].append({
                'file': file_path.name,
                'pattern': 'EXCEPTION',
                'error': str(e)
            })
            print()
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("=" * 70)
    print("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    print(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total']}")
    print(f"æˆåŠŸ: {stats['success']} ({stats['success']/stats['total']*100:.1f}%)")
    print(f"å¤±æ•—: {stats['failed']} ({stats['failed']/stats['total']*100:.1f}%)")
    if insert_to_bq:
        print(f"BigQueryæŠ•å…¥: {stats['inserted']} ({stats['inserted']/stats['total']*100:.1f}%)")
    print()
    
    print("ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥:")
    for pattern, count in sorted(stats['by_pattern'].items(), key=lambda x: x[1], reverse=True):
        print(f"  {pattern}: {count} ({count/stats['total']*100:.1f}%)")
    print()
    
    if stats['errors']:
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°(æœ€åˆã®5ä»¶):")
        for error in stats['errors'][:5]:
            print(f"  - {error['file']}: {error['error'][:50]}...")
        print()
    
    return stats


if __name__ == "__main__":
    print("=" * 80)
    print("ğŸ”§ Universal Announcement Parser v7 - å®Œå…¨ç‰ˆ")
    print("=" * 80)
    print()
    print("âœ… å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½:")
    print("  1. and/orå„ªå…ˆé †ä½ã®ãƒã‚°ä¿®æ­£")
    print("  2. ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–åŸºç›¤")
    print("  3. ãƒ‘ãƒ¼ã‚µãƒ¼ç²¾åº¦ã®å‘ä¸Š")
    print("     - TableParserV4ã®æ”¹å–„")
    print("     - ã€ŒåŒæ³•ã€å‚ç…§ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³å˜ä½ãƒªã‚»ãƒƒãƒˆ")
    print("     - é˜²å¾¡çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°")
    print("  4. å…¨4ãƒ‘ãƒ¼ã‚µãƒ¼ã®æ­£è¦åŒ–å¯¾å¿œ")
    print()
    print("=" * 80)
    print()
    print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆ10ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
    print("  2. å…¨ä»¶å‡¦ç†ï¼ˆ179ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
    print("  3. é›†è¨ˆé¡ã®æ¤œè¨¼")
    print("=" * 80)